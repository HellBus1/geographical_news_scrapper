{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import library-library\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation and Preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "# Word Embedding\n",
    "import joblib\n",
    "from keybert import KeyBERT\n",
    "kw_extractor = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "# Input and Expansion Query\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "from yake import KeywordExtractor\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "NLTK_StopWords = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(berita):\n",
    "    s = berita.lower()\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = s.replace('\\r', ' ')\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    T = [t for t in tokens if (((t.lower() == \"tempat\") or (t.lower() == \"waktu\") or (t.lower() == \"hari\")) or (t not in NLTK_StopWords))]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bangke', 'siskkskwoa', 'dsd']\n"
     ]
    }
   ],
   "source": [
    "kta=\"bangke siskkskwoa dsd\"\n",
    "print(preprocessing(kta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158 entries, 0 to 157\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        158 non-null    object\n",
      " 1   date         158 non-null    object\n",
      " 2   description  158 non-null    object\n",
      " 3   source       158 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.2+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------------\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "df_test = df_test[pd.notnull(df_test['description'])]\n",
    "print(df_test.info())\n",
    "print ('-'*90)\n",
    "document_text_test= joblib.load('document_text_test.pkl')\n",
    "print(len(document_text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1418 entries, 0 to 1418\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        1418 non-null   object\n",
      " 1   date         1418 non-null   object\n",
      " 2   description  1418 non-null   object\n",
      " 3   source       1418 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 55.4+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------------\n",
      "1419\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_train = df_train[pd.notnull(df_train['description'])]\n",
    "print(df_train.info())\n",
    "print ('-'*90)\n",
    "document_text_train= joblib.load('document_text_train.pkl')\n",
    "print(len(document_text_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_read(bow):\n",
    "    bow_read = pd.read_csv(bow)\n",
    "    bow_text = []\n",
    "\n",
    "    for i in range(0,bow_read.shape[0]):\n",
    "        bow_text.append(bow_read.iloc[i,1])\n",
    "        \n",
    "    return(bow_read,bow_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cari_dokpertama(kueriAsli):\n",
    "    kueriPre=preprocessing(kueriAsli)\n",
    "    kueriPre= \" \".join (kueriPre)\n",
    "    hasilSearch=[]\n",
    "    tfidf_train = joblib.load('tfidf_train.pkl')\n",
    "    tfidf_vectorizer = joblib.load('vectorizer.pkl')\n",
    "    query_vec= tfidf_vectorizer.transform([kueriPre])\n",
    "    # print('queryvec')\n",
    "    print(query_vec)\n",
    "    results=cosine_similarity(tfidf_train, query_vec).reshape((-1))\n",
    "    # print(results)\n",
    "    for i in results.argsort()[-5:][::-1]:\n",
    "        hasilSearch.append(df_train.iloc[i,-2])\n",
    "    hasilSearch=\". \".join(hasilSearch)\n",
    "    return hasilSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Keywords Extraction with YAKE\n",
    "def keyword_yake(hasilSearch):\n",
    "    # print(hasilSearch)\n",
    "    keywordYake=[]\n",
    "\n",
    "    k_extractor = KeywordExtractor(lan=\"id\", n=1, top=50)\n",
    "    # print(k_extractor)\n",
    "    k_extractor2 = KeywordExtractor(lan=\"id\", n=2, top=50)\n",
    "    # print(k_extractor2)\n",
    "    keywords = k_extractor.extract_keywords(text=hasilSearch)\n",
    "    # print(\"pertama : \",keywords)\n",
    "    keywords = k_extractor2.extract_keywords(text=hasilSearch)\n",
    "    # print(\"kedua : \",keywords)\n",
    "    keywordYake = [x for x, y in keywords]\n",
    "    # print(keywordYake)\n",
    "    #keywordYake.append(keywords)\n",
    "    # print (keywordYake)\n",
    "    return keywordYake\n",
    "#print(\"Keywords of article\\n\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with TFIDF\n",
    "def keyword_tfidf(hasilSearch):\n",
    "\n",
    "    keywordtfidf=[]\n",
    "    keywordtfidf2=[]\n",
    "\n",
    "    #doc = 'بَاب فرض الْوضُوء وسننه وهيآته وَفرض الْوضُوء سِتّ خِصَال النِّيَّة عمند غسل الْوَجْه وَغسل الْوَجْه وَغسل الذراعين مَعَ الْمرْفقين وَمسح مَا قل من الرَّأْس وَغسل الرجلَيْن مَعَ الْكَعْبَيْنِ وَالتَّرْتِيب وعَلى قَول الْوَلَاء وسننه عشر خِصَال خمس مِنْهَا قبل غسل الْوَجْه وَهِي التَّسْمِيَة وَغسل الْكَفَّيْنِ والمضمضة وَالِاسْتِنْشَاق وَالْمُبَالغَة فيههما إِلَّا للصَّائِم وَخمْس بعد غسل الْوَجْه وَهِي تَقْدِيم الْيُمْنَى على ليسرى وَمسح جَمِيع الرَّأْس وَمسح الْأُذُنَيْنِ ظاهرهما وباطنهما وَإِدْخَال الأصبعين فيهمَا وتخليل أَصَابِع الرجلَيْن . وَغسل دَاخل الْكَعْبَيْنِ وَلَيْسَ مسح لعنق من سنَنه وفضيلته تكراره ثَلَاثًا وزالواجب فِيهِ مرّة والمرتان أفضل وَالثَّلَاث أكمل وهيآته أَن يبْدَأ فِي تَطْهِير الْأَعْضَاء بمواضع الِابْتِدَاء . فَإِن اقْتصر على فروضه استة أَجزَأَهُ وَإِن ضيع حَظّ نَفسه فِيمَا ترك'\n",
    "    total_words = re.sub(r'[^\\w]', ' ', hasilSearch)\n",
    "    total_words = total_words.lower().split()\n",
    "    #print (total_words)\n",
    "    total_word_length = len(total_words)\n",
    "    total_sentences = tokenize.sent_tokenize(hasilSearch)\n",
    "    total_sent_len = len(total_sentences)\n",
    "\n",
    "    tf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in tf_score:\n",
    "                tf_score[each_word] += 1\n",
    "            else:\n",
    "                tf_score[each_word] = 1\n",
    "\n",
    "    # Dividing by total_word_length for each dictionary element\n",
    "    tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "    #print(tf_score)\n",
    "    def check_sent(word, sentences): \n",
    "        final = [all([w in x for w in word]) for x in sentences] \n",
    "        sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "        return int(len(sent_len))\n",
    "\n",
    "    idf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in idf_score:\n",
    "                idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "            else:\n",
    "                idf_score[each_word] = 1\n",
    "\n",
    "    # Performing a log and divide\n",
    "    idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "    #print(idf_score)\n",
    "    tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "    #print(tf_idf_score)\n",
    "    def get_top_n(dict_elem, n):\n",
    "        result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "        hasil =list(result.keys())\n",
    "        #print(list(result.keys()))        \n",
    "        return hasil\n",
    "    #print(get_top_n(tf_idf_score, 25))\n",
    "    #print(len(get_top_n(tf_idf_score, 1)))\n",
    "    keywordtfidf.append(get_top_n(tf_idf_score, 35))\n",
    "    for i in range(len(keywordtfidf)):\n",
    "        #print (i)\n",
    "        totalKw=0\n",
    "        totalKw=len(keywordtfidf[i])\n",
    "        for j in range(totalKw):\n",
    "            #print (j)\n",
    "            keywordtfidf2.append(keywordtfidf[i][j])\n",
    "    #print (keywordtfidf2)\n",
    "    return keywordtfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with BERT\n",
    "def keyword_bert(hasilSearch):\n",
    "    # print(hasilSearch)\n",
    "\n",
    "    keywordbert=[]\n",
    "\n",
    "    #for j in range(len(array_text)):\n",
    "    keyword1 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 1))\n",
    "    # print(keyword1)\n",
    "    keyword2 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 2))\n",
    "    # print(keyword2)\n",
    "    # keyword3 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 5))\n",
    "    # print(keyword3)\n",
    "\n",
    "    #print(\"Keywords of article\\n\", keywords)\n",
    "    for i in range (0,len (keyword1)):\n",
    "        keywordbert.append(keyword1[i][0])\n",
    "        keywordbert.append(keyword2[i][0])\n",
    "    # print (keywordbert)\n",
    "    return keywordbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rangking (keywordGabung):\n",
    "    keywordTemp=[]\n",
    "    keywordFinal=[]\n",
    "\n",
    "    def borda_sort(lists):\n",
    "        scores = {}\n",
    "        for l in lists:\n",
    "            for idx, elem in enumerate(reversed(l)):\n",
    "                if not elem in scores:\n",
    "                    scores[elem] = 0\n",
    "                scores[elem] += idx\n",
    "        return sorted(scores.keys(), key=lambda elem: scores[elem], reverse=True)\n",
    "\n",
    "    keywordTemp.append(borda_sort(keywordGabung))\n",
    "    print ('kandidat temp',keywordTemp)\n",
    "    print ('Total Kandidat temp: ',len(keywordTemp[0]))\n",
    "\n",
    "    if len(keywordTemp[0])>30:\n",
    "        print ('kurang dari 80')\n",
    "        for i in range (0,80):\n",
    "            keywordFinal.append(keywordTemp[0][i])\n",
    "    elif len(keywordTemp[0])<80:\n",
    "        print ('lebih dari 80')\n",
    "        for i in range (0,len(keywordTemp)):\n",
    "            for j in range (0,len(keywordTemp[0])):\n",
    "                keywordFinal.append(keywordTemp[0][j])\n",
    "    print ('Total Kandidat final: ',len(keywordFinal))\n",
    "    print ('Kandidat final: ',keywordFinal)\n",
    "    return keywordFinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_BOW(keywordBOW, kueriAsli):\n",
    "    cekDuplicate = []\n",
    "    kandidatFix = []\n",
    "\n",
    "    for i in keywordBOW:\n",
    "        if(i not in cekDuplicate and i!=0):\n",
    "            cekDuplicate.append(i)\n",
    "\n",
    "    # queries=[kueriAsli]\n",
    "    queries=kueriAsli\n",
    "    query_embeddings = embedder.encode(queries)\n",
    "    corpus_embeddings4 = embedder.encode(cekDuplicate)\n",
    "    \n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    closest_n = 1000\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings4, 'cosine')[0]\n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            kandidatFix.append(cekDuplicate[idx])\n",
    "    return kandidatFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kandidatFix(kueriAsli,bow):\n",
    "    #kueri what\n",
    "    # kueriAsli='apa sebenarnya kejadian yang terjadi diberita tersebut'\n",
    "    kueri=preprocessing(kueriAsli)\n",
    "    kueri= [\" \".join (kueri)]\n",
    "    print (kueri)\n",
    "    hasilkandidat=[]\n",
    "    keywordGabung=[]\n",
    "    kandidatFix=[]\n",
    "    kueriFix=[]\n",
    "    kueriFixWithDelimiter=[]\n",
    "    \n",
    "\n",
    "\n",
    "    hasilSearch=cari_dokpertama(kueriAsli)\n",
    "    keywordYake=keyword_yake(hasilSearch)\n",
    "    keywordtfidf2=keyword_tfidf(hasilSearch)\n",
    "    keywordbert=keyword_bert (hasilSearch)\n",
    "    keywordBOW=keyword_BOW(bow, kueri)\n",
    "\n",
    "    keywordGabung.append(keywordYake)\n",
    "    keywordGabung.append(keywordtfidf2)\n",
    "    keywordGabung.append(keywordbert)\n",
    "    # keywordGabung.append(keywordBOW)\n",
    "    hasilrank=rangking(keywordGabung)\n",
    "\n",
    "    for i in hasilrank:\n",
    "        kueriFix.append(i)\n",
    "    for x in keywordBOW:\n",
    "        kueriFix.append(x)\n",
    "    for j in kueriFix:\n",
    "        hasilkandidat.append(j)\n",
    "    kueriFixWithDelimiter=kueriFix\n",
    "    kueriFix=[preprocessing(i) for i in kueriFix]\n",
    "    for i in kueriFix:\n",
    "        for j in i:\n",
    "            kandidatFix.append(j)\n",
    "    kandidatFix= [\" \".join (kandidatFix)]\n",
    "    \n",
    "    print ('*'*120)\n",
    "    return(kandidatFix,keywordGabung,keywordBOW,hasilrank,kueriFixWithDelimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_kecelakaan_read,bow_kecelakaan_text = bow_read('bow_kecelakaan.csv')\n",
    "bow_where_read,bow_where_text = bow_read('bow_where.csv')\n",
    "bow_when_read,bow_when_text = bow_read('bow_when.csv')\n",
    "bow_who_read,bow_who_text = bow_read('bow_who.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What     :  kecelakaan\n",
      "Where    :  surabaya\n",
      "When     :  waktu\n",
      "Who      :  pelaku\n"
     ]
    }
   ],
   "source": [
    "print(\"What     : \", bow_kecelakaan_text[0])\n",
    "print(\"Where    : \", bow_where_text[0])\n",
    "print(\"When     : \", bow_when_text[0])\n",
    "print(\"Who      : \", bow_who_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hari waktu']\n",
      "  (0, 15272)\t0.7793618298836754\n",
      "  (0, 5342)\t0.6265741281926417\n",
      "kandidat temp [['menimbulkan', 'menabrak pengemudinya', '2022', '2022 peristiwa', 'pengemudinya', '2021 korban', '2021', '2021 petugas', 'menemukan', 'sunberejo kecamatan', 'kecamatan', 'lingkungan sunberejo', 'tangerang', 'pengemudi', 'menemukan kerusakan', 'jalanan meningkat', 'meningkat', 'menyuruh penumpang', 'meneruskan', 'jumat 12', 'menyeberang', '13 2021', 'pengendara', '2021 yudha', 'menaruh', 'tertabrak menyeberang', 'lingkungan', '11 2021', 'sunberejo', 'menyeberang berlanjut', 'junaedi', 'menabrak kendaraan', 'pengelolaan', 'kecamatan gandusari', 'terjangkau', 'meningkat ketimbang', 'mendadak', '1018', 'lokasi menyeberang', 'kekhawatiran', 'menimbulkan kerugian', 'kerusakan', 'meneruskan perjalanan', 'korban meninggal', 'penampungan', '16 2022', 'kecelakaan menabrak', 'jumat', 'penyeberang', 'menyeberang lintasan', 'dipersilahkan', 'jalan meninggal', 'truk tangki', 'menyediakan', 'meninggal dunia', 'menyeberang jalan', 'tangki pertamina', 'jalanan', 'madiun kota', 'menabrak pembatas', 'kota madiun', 'pengganti', 'tangki putu', 'kecelakaan menaruh', 'madiun taksi', 'juta', 'dunia aris', 'korban menyeberang', 'putu putu', 'menabrak', 'dunia lokasi', 'ukuran pembatas', 'tean truk', 'menyuruh', 'tertabrak truk', 'tertabrak pengendara', 'menuntun sepeda', 'ketimbang', 'sepeda angin', 'merah putu', 'keterangan', 'bak sampah', 'sepeda meninggal', 'kapolres madiun', 'kendaraan', '12', 'penumpang', 'taksi berhenti', '21', 'jalanan kekhawatiran', 'pembatas jalan', 'soekarno', 'kapolres', 'alhamdulillah', 'wib truk', 'akbp', 'perjalanan menemukan', 'jalan', 'dewa', 'nugroho', 'kendaraan taksi', 'menyala', 'slamet', 'eka', 'menabrak korban', 'winarko taksi', 'darmawan', 'meninggal', 'truk', 'sabtu', 'berpotensi menabrak', 'dewa putu', 'kecelakaan', 'putu eka', 'budiarto', '14 2021', 'sampah', '49', 'kereta', 'madiun', 'gandusari melaju', 'hatta', 'ukuran', 'menyala merah', 'berbelok', 'jalan terjangkau', 'aris winarko', 'simpang', 'putu', 'tean', 'berlanjut menabrak', 'madiun korban', 'berlanjut', 'putu kanit', 'meninggal tempat', 'truk menabrak', 'traffic', 'slamet budiarto', 'light', 'dinas lingkungan', 'tangki', 'gandusari', 'dunia', 'gakkum', 'alhamdulillah pengemudi', 'akbp dewa', 'satlantas', 'masyarakat', 'eka darmawan', 'winarko', 'kecamatan talun', 'soekarno hatta', 'bernopol', 'hatta berbelok', 'ae', 'lintasan menyuruh', 'simpang tean', 'khawatirnya', 'traffic light', 'ub', 'mendadak sebentar', 'light menyala', 'dikemudikan', 'tertabrak', 'gakkum satlantas', '65', 'nugroho mcb', 'yos sudarso', 'yos', 'pengemudi selamat', 'sudarso', 'meningkat pemkot', 'selamat penyeberang', 'singkong', 'korban', 'selamat', 'menyeberang menuntun']]\n",
      "Total Kandidat temp:  177\n",
      "kurang dari 80\n",
      "Total Kandidat final:  80\n",
      "Kandidat final:  ['menimbulkan', 'menabrak pengemudinya', '2022', '2022 peristiwa', 'pengemudinya', '2021 korban', '2021', '2021 petugas', 'menemukan', 'sunberejo kecamatan', 'kecamatan', 'lingkungan sunberejo', 'tangerang', 'pengemudi', 'menemukan kerusakan', 'jalanan meningkat', 'meningkat', 'menyuruh penumpang', 'meneruskan', 'jumat 12', 'menyeberang', '13 2021', 'pengendara', '2021 yudha', 'menaruh', 'tertabrak menyeberang', 'lingkungan', '11 2021', 'sunberejo', 'menyeberang berlanjut', 'junaedi', 'menabrak kendaraan', 'pengelolaan', 'kecamatan gandusari', 'terjangkau', 'meningkat ketimbang', 'mendadak', '1018', 'lokasi menyeberang', 'kekhawatiran', 'menimbulkan kerugian', 'kerusakan', 'meneruskan perjalanan', 'korban meninggal', 'penampungan', '16 2022', 'kecelakaan menabrak', 'jumat', 'penyeberang', 'menyeberang lintasan', 'dipersilahkan', 'jalan meninggal', 'truk tangki', 'menyediakan', 'meninggal dunia', 'menyeberang jalan', 'tangki pertamina', 'jalanan', 'madiun kota', 'menabrak pembatas', 'kota madiun', 'pengganti', 'tangki putu', 'kecelakaan menaruh', 'madiun taksi', 'juta', 'dunia aris', 'korban menyeberang', 'putu putu', 'menabrak', 'dunia lokasi', 'ukuran pembatas', 'tean truk', 'menyuruh', 'tertabrak truk', 'tertabrak pengendara', 'menuntun sepeda', 'ketimbang', 'sepeda angin', 'merah putu']\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "hasilDokumenWhen=[]\n",
    "# hasilDokumenWho=[]\n",
    "# hasilDokumenWhere=[]\n",
    "# hasilDokumenWhat=[]\n",
    "\n",
    "# kueriAsliWhat='apa sebenarnya kejadian kecelakaan yang terjadi diberita tersebut'\n",
    "# kueriAsliWhat='musibah apa yang terjadi'\n",
    "# kueriAsliWhere='daerah lokasi tempat terjadinya kecelakaan'\n",
    "# kueriAsliWhere='kota kejadian terjadi'\n",
    "# kueriAsliWho='siapa pelaku kejadian ini'\n",
    "kueriAsliWhen='hari apa waktu terjadinya'\n",
    "\n",
    "# kandidatFixWhat,keywordGabungWhat,keywordBOW_What, hasilrankWhat, kueriFixWithDelimiter_What = kandidatFix(kueriAsliWhat, bow_kecelakaan_text)\n",
    "# kandidatFixWhere,keywordGabungWhere,keywordBOW_Where, hasilrankWhere,kueriFixWithDelimiter_Where = kandidatFix(kueriAsliWhere, bow_where_text)\n",
    "# kandidatFixWho,keywordGabungWho,keywordBOW_Who, hasilrankWho, kueriFixWithDelimiter_Who = kandidatFix(kueriAsliWho, bow_who_text)\n",
    "kandidatFixWhen,keywordGabungWhen,keywordBOW_When, hasilrankWhen, kueriFixWithDelimiter_When = kandidatFix(kueriAsliWhen, bow_when_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harinya', 'seharinya', 'hari', 'zamannya', 'dihari', 'berhari', 'sehari', 'siangnya', 'masanya', 'ajalku', 'ajalnya', 'waktunya', 'jamannya', 'ajal', 'seharian', 'zaman', 'diwaktu', 'dizaman', 'siang', 'waktu', 'purnawaktu', 'jaman', 'dinihari', 'sejam', 'masa', 'hariku', 'bermasa', 'harimu', 'semasa', 'saat', 'perhari', 'menitnya', 'detik', 'saatnya', 'dimasa', 'subuh', 'pekan', 'detiknya', 'tempoh', 'pertanggal', 'vonis', 'sesaat', 'pagi', 'berjam', 'paginya', 'apabila', 'suatu', 'pertahun', 'tahunya', 'tahunnya', 'seiringnya', 'ketika', 'sewaktu', 'eranya', 'kisaran', 'tahun', 'penayangannya', 'sempat', 'sebelum', 'disaat', 'sekon', 'kemarin', 'deret', 'yadnya', 'kondangan', 'sabtu', 'ramadan', 'kemauannya', 'tayangan', 'menit', 'diawal', 'imbang', 'minggu', 'hitungan', 'mendatar', 'dilokasi', 'berselang', 'secondes', 'jam', 'ruwatan', 'masing', 'era', 'tiba', 'perkuliahan', 'penanggalan', 'sambil', 'lembarnya', 'raihaanun', 'menjelang', 'perkata', 'tanggalnya', 'nyaris', 'babak', 'kendati', 'jumat', 'pekannya', 'berjumlah', 'selagi', 'gebyar', 'disiang', 'dasarnya', 'manakala', 'sejenak', 'tarikh', 'peluruhan', 'kendatipun', 'penghulu', 'berbadai', 'maka', 'jumlah', 'pemungutan', 'dilangsungkan', 'kerap', 'berurutan', 'ketebalannya', 'bainai', 'arakan', 'tertentu', 'ribu', 'dipagi', 'kartana', 'setalah', 'keterlambatan', 'pemutarannya', 'yg', 'chansung', 'saking', 'gelaran', 'setangkup', 'malaman', 'andraini', 'kegiatannya', 'penayangan', 'tersendiri', 'menyantap', 'telanjur', 'peramalan', 'gemangnya', 'pengda', 'semalam', 'ratus', 'kesibukannya', 'luarnya', 'pencabutan', 'diperas', 'sesingkat', 'onsd', 'hajatan', 'aktivitasnya', 'sedangkan', 'ditaburi', 'ketahuan', 'suntuk', 'ditempat', 'lamanya', 'khitanan', 'yakni', 'diukur', 'volt', 'semenjak', 'petang', 'reda', 'repot', 'perangan', 'penjelmaan', 'ketebalan', 'pinggir', 'pengeraman', 'telat', 'meneken', 'maksimum', 'sekarat', 'almamaternya', 'tepakyang', 'lintasnya', 'senandung', 'dungulan', 'taksiran', 'rajaban', 'rapatan', 'ytse', 'jamuan', 'penentuan', 'tanggal', 'berderet', 'sepanjang', 'cungkring', 'tempat', 'setebal', 'menjebak', 'hubung', 'bisikan', 'tatkala', 'dijemur', 'iyatul', 'dimatangkan', 'kaping', 'perjumlahan', 'pendataan', 'persebaya', 'haripun', 'satuannya', 'dakika', 'kalau', 'jumadil', 'resepsi', 'שבת', 'pada', 'kejurnas', 'bermalam', 'bergulirnya', 'kaget', 'pemutaran', 'cembung', 'terkenang', 'mince', 'sepekan', 'usd', 'pakasa', 'syaban', 'siwan', 'pepet', 'kujelang', 'witir', 'mana', 'nyepi', 'nadanya', 'disekitar', 'perjalannya', 'dikala', 'aksis', 'awal', 'bersam', 'menerkam', 'kemunculannya', 'seraya', 'dikocok', 'gubuk', 'dihaluskan', 'adlen', 'motzei', 'anno', 'allaihi', 'kesukaran', 'pencatatan', 'paska', 'kurva', 'kisah', 'maret', 'karir', 'kegiatan', 'malah', 'bercucuk', 'ketepatan', 'pelataran', 'tirakatan', 'siklus', 'pemecatan', 'galamai', 'saja', 'saklar', 'cuti', 'lusin', 'dasa', 'estimasi', 'mbyte', 'kesudahannya', 'cuplikan', 'atraksi', 'kenduri', 'tayangnya', 'syebat', 'terbenamnya', 'pingsan', 'pulalah', 'tatanan', 'diaduk', 'kalibrasi', 'jabar', 'darma', 'mulud', 'ratap', 'narasi', 'serangkai', 'survei', 'sapar', 'optimal', 'kabisat', 'kasmaran', 'tugas', 'selang', 'di', 'tumbilo', 'puluh', 'invers', 'kelengkungan', 'hayat', 'sesuai', 'dzuhur', 'ditunda', 'bersangkutan', 'saptaresi', 'pertandingan', 'pengesahan', 'ronde', 'digoreng', 'acara', 'sedari', 'periode', 'bergegas', 'terlelap', 'kapasitansi', 'seollal', 'pancawara', 'awatara', 'penyamaran', 'galungan', 'sirna', 'pelaksanaan', 'birkat', 'grasi', 'takbiran', 'nunggu', 'menguap', 'aruh', 'tertunda', 'numerik', 'pengabdiannya', 'sepersejuta', 'durasinya', 'sebelumnya', 'durasi', 'kala', 'takbir', 'cerita', 'dekade', 'jangkauan', 'zuhur', 'torsi', 'menyegi', 'direbus', 'jeda', 'minggunya', 'rudra', 'dimasak', 'puasa', 'tết', 'putaran', 'sehar', 'kegelisahan', 'malamnya', 'diadakan', 'musim', 'rentang', 'penjumlahan', 'lodaya', 'esuk', 'menyusul', 'sebanyak', 'kurun', 'esoknya', 'waisak', 'per', 'muharam', 'maksimal', 'selama', 'dirubah', 'penjadwalannya', 'senggang', 'erg', 'sundal', 'tetapan', 'direndam', 'bersegi', 'pertandigan', 'gondrong', 'akhirnya', 'pergelaran', 'hilir', 'nyadran', 'penyebut', 'pasca', 'pemodelan', 'peluk', 'kelajuan', 'periodenya', 'mudik', 'malam', 'alokasi', 'rakik', 'cest', 'sausan', 'esok', 'senggangnya', 'akhir', 'pon', 'ngeplang', 'samping', 'semenatara', 'sore', 'yaitu', 'kst', 'aktivitas', 'rayakan', 'sunatan', 'menyusuri', 'inkarnasi', 'dikemudian', 'dihutan', 'sehingga', 'dimalam', 'ton', 'mev', 'serie', 'terabit', 'nukrashi', 'menjalani', 'pora', 'macet', 'terlewati', 'sendiri', 'ketukan', 'rojak', 'dasawarsa', 'abad', 'sana', 'sisinya', 'segera', 'persiraja', 'populasi', 'ramunia', 'rebo', 'supaya', 'perkerjaan', 'bubarnya', 'adven', 'enggan', 'peparnas', 'alurnya', 'stipulasi', 'sukat', 'manu', 'upacara', 'penerbitannya', 'diproses', 'sekaten', 'infotama', 'maksimumnya', 'ἑξήκοντα', 'presesi', 'maghrib', 'kecepatan', 'tayang', 'situ', 'paskah', 'kepergian', 'mau', 'tersingkat', 'onom', 'tangis', 'wita', 'setiap', 'inet', 'malahan', 'kalo', 'agar', 'abjad', 'kelab', 'berpuasa', 'pertandingannya', 'sebelahnya', 'optimasi', 'keduapuluh', 'tahapan', 'tiap', 'untuk', 'sembari', 'penyandian', 'lantaran', 'jabatannya', 'pun', 'konate', 'dihabiskan', 'seklai', 'mbit', 'priode', 'yang', 'persamuan', 'solat', 'musimnya', 'simpul', 'saaks', 'dirangkai', 'piksel', 'dibulan', 'semalaman', 'peringati', 'semester', 'setahun', 'kemudian', 'dimusim', 'berekreasi', 'tenggang', 'setelahnya', 'disamping', 'mengurutkan', 'fatihah', 'rakaat', 'idul', 'berjamaah', 'mengulur', 'usb', 'berpantang', 'penginjilan', 'tgl', 'dugderan', 'gulbis', 'sementara', 'didinginkan', 'wsp', 'diringkas', 'konsentrik', 'gaji', 'menanti', 'berkesempatan', 'didikte', 'seseorang', 'pernah', 'romlah', 'shema', 'bita', 'idulfitri', 'berlindung', 'bulan', 'линия', 'impedansi', 'seumur', 'redite', 'kirab', 'ketempat', 'ditaruh', 'memperhitungkan', 'dipadatkan', 'nataru', 'sensus', 'featurette', 'tertidur', 'berjalannya', 'ekuinoks', 'dongeng', 'kendala', 'pelolong', 'kehidupan', 'iedul', 'bila', 'perhitungan', 'amplitudo', 'tempatnya', 'kubik', 'penghentian', 'ataupun', 'nauchnyj', 'hsdpa', 'pahing', 'rukuk', 'dosis', 'pelariannya', 'rokan', 'sampingnya', 'ganesa', 'rangaian', 'denhanud', 'eiso', 'lantas', 'dilelehkan', 'diperpendek', 'btu', 'dioesis', 'dua', 'kemudia', 'panjang', 'bersanggol', 'pikiran', 'jelang', 'lebaran', 'bubar', 'upacaranya', 'perkiraan', 'selebar', 'semangatnya', 'laga', 'mendarat', 'walau', 'ditiriskan', 'dilarutkan', 'berjalanya', 'semua', 'imbuhan', 'bekerja', 'librasi', 'terlanjur', 'farad', 'menghabiskan', 'idhul', 'stuiver', 'nyenyak', 'perkampungan', 'kepergiannya', 'tebalnya', 'kiprahnya', 'karenakan', 'berdurasi', 'bulannya', 'perhitungannya', 'utc', 'disuatu', 'sebesar', 'sanksi', 'rabu', 'fluks', 'usai', 'maulid', 'pengirikan', 'tnggal', 'saniscara', 'rintihan', 'penyambutan', 'djam', 'serta', 'ramadhan', 'pesta', 'prosesi', 'ditumbuk', 'finis', 'bacai', 'asumsi', 'jst', 'seminggu', 'tahlilan', 'justru', 'saka', 'sadranan', 'jadinya', 'berlibur', 'edt', 'ditumis', 'remisi', 'pengujian', 'disetiap', 'dicuci', 'dimeriahkan', 'spasi', 'dimana', 'lomban', 'menghampiri', 'apskritis', 'berkuliah', 'lebarnya', 'layak', 'wicara', 'ini', 'tangen', 'pembelahan', 'atas', 'wasu', 'dengan', 'disore', 'besok', 'kuantan', 'rabiul', 'dipendekkan', 'diakibatkan', 'cpu', 'kembalinya', 'fase', 'dipersingkat', 'dipanggang', 'hidup', 'ipv', 'inchi', 'wib', 'pekerjaaan', 'karier', 'singgah', 'meski', 'wsk', 'seruuu', 'berwisata', 'kamis', 'sideris', 'pudar', 'sesudahnya', 'iyat', 'semuanya', 'iapun', 'sekaliannya', 'padahal', 'umanis', 'pelajaran', 'menentukan', 'diluncurkan', 'seratus', 'dikurung', 'akibat', 'defile', 'catatannya', 'oktaf', 'pacaran', 'istu', 'kbit', 'sini', 'rol', 'pekerjaan', 'kalpa', 'berbaring', 'meluangkan', 'disebabkan', 'dihitung', 'perilisannya', 'panjangnya', 'riwayat', 'dalamnya', 'kelulusan', 'selain', 'cenderung', 'serinya', 'aktingnya', 'penangguhan', 'kkal', 'bertakhta', 'berpengaruh', 'konstanta', 'bertekad', 'centi', 'kameng', 'untunglah', 'pemerintahan', 'sekalipun', 'keesokan', 'birama', 'empat', 'jelas', 'tenggat', 'quadratura', 'berlalunya', 'trilyun', 'disini', 'sarjananya', 'setibanya', 'sejak', 'diperingati', 'kesadaran', 'berbangkit', 'telah', 'peluncuran', 'analisa', 'berminggu', 'interupsi', 'sarapan', 'begitu', 'diubah', 'manwantara', 'mandi', 'magrib', 'duit', 'miliar', 'usaha', 'natal', 'tugasnya', 'kerena', 'berbuka', 'safar', 'luang', 'kesusahan', 'ajang', 'jeritan', 'persembunyian', 'sambutlah', 'tbit', 'kalender', 'menyumpah', 'nanti', 'dan', 'disitu', 'berpesta', 'sampai', 'melebihi', 'baranang', 'sebulan', 'terjaga', 'mempersingkat', 'sehat', 'legenda', 'minimun', 'hakikatnya', 'dikurangi', 'kekuatannya', 'miliyar', 'jugalah', 'dipilah', 'rehat', 'hadapannya', 'meskipun', 'peluncurannya', 'pelayanan', 'kekuasaan', 'bombom', 'konduktansi', 'marrio', 'penghujung', 'tiga', 'interval', 'tevet', 'berikutnya', 'dicelupkan', 'enjing', 'tertanggal', 'ulangtahunnya', 'diinkubasi', 'diameternya', 'liburan', 'probabilitas', 'obon', 'fungsinya', 'lunisolar', 'regresi', 'lalu', 'gritte', 'mulai', 'pembebasannya', 'menjumlahkan', 'karena', 'diferensial', 'sesampai', 'profesi', 'pengamatan', 'duluan', 'selamatan', 'hidupnya', 'liburnya', 'perjalanannya', 'disiram', 'tandang', 'shalat', 'petiklah', 'pukul', 'dukut', 'kesengsaraan', 'memaksa', 'terakhir', 'mengakibatkan', 'kilometernya', 'impera', 'melodi', 'karenanya', 'walaupun', 'adaptor', 'kalkulasi', 'kamarnya', 'penundaan', 'pengembaraannya', 'nyx', 'mengingat', 'berbisnis', 'rame', 'tabulasi', 'istirahat', 'km³', 'roset', 'pkl', 'menyebabkan', 'petualangan', 'dicampurkan', 'longueau', 'kuota', 'pasalnya', 'liter', 'lulusnya', 'senin', 'beberapa', 'mengabiskan', 'jadi', 'capable', 'selanjutnya', 'setlah', 'selasa', 'dirilisnya', 'bujang', 'integer', 'atau', 'kapankah', 'urusannya', 'apalagi', 'leg', 'antaranya', 'nada', 'atasnya', 'sunah', 'tigapuluh', 'sanhá', 'perwaliannya', 'halloween', 'larik', 'mmol', 'maariv', 'pencobaan', 'kepulangannya', 'hayatnya', 'inersia', 'direnggangkan', 'seusai', 'piknik', 'sekedar', 'turnya', 'lulus', 'wudhu', 'guring', 'meninggalnya', 'm³', 'pelayanannya', 'bisnis', 'bahkan', 'desember', 'biliun', 'seabad', 'keahliannya', 'kalaupun', 'memprediksi', 'triliun', 'keesokkan', 'kareba', 'porda', 'biarpun', 'kerana', 'seandainya', 'mb', 'dadanya', 'ahad', 'dekatnya', 'bergana', 'selalu', 'legi', 'device', 'kukuk', 'sepeninggal', 'observasi', 'diiris', 'penghitungan', 'prediksi', 'gbit', 'tambangan', 'mukamu', 'awalan', 'terakhirnya', 'juta', 'etoh', 'berjemur', 'mengukur', 'junho', 'berikut', 'pembukaannya', 'boleh', 'intro', 'def', 'baris', 'sebab', 'melepas', 'dikarenakan', 'tibalah', 'jika', 'kcal', 'rajab', 'pst', 'magang', 'minimal', 'console', 'syukuran', 'kilogram', 'berlalu', 'sengkala', 'frekuensi', 'afshin', 'hemera', 'milidetik', 'mg', 'terpaksa', 'sekadar', 'demonstrasi', 'raster', 'bit', 'operasinya', 'terjebak', 'sebaliknya', 'sholat', 'lelap', 'perhelatan', 'stelah', 'tidurnya', 'centimeter', 'penyesalan']\n",
      "['menimbulkan', 'menabrak pengemudinya', '2022', '2022 peristiwa', 'pengemudinya', '2021 korban', '2021', '2021 petugas', 'menemukan', 'sunberejo kecamatan', 'kecamatan', 'lingkungan sunberejo', 'tangerang', 'pengemudi', 'menemukan kerusakan', 'jalanan meningkat', 'meningkat', 'menyuruh penumpang', 'meneruskan', 'jumat 12', 'menyeberang', '13 2021', 'pengendara', '2021 yudha', 'menaruh', 'tertabrak menyeberang', 'lingkungan', '11 2021', 'sunberejo', 'menyeberang berlanjut', 'junaedi', 'menabrak kendaraan', 'pengelolaan', 'kecamatan gandusari', 'terjangkau', 'meningkat ketimbang', 'mendadak', '1018', 'lokasi menyeberang', 'kekhawatiran', 'menimbulkan kerugian', 'kerusakan', 'meneruskan perjalanan', 'korban meninggal', 'penampungan', '16 2022', 'kecelakaan menabrak', 'jumat', 'penyeberang', 'menyeberang lintasan', 'dipersilahkan', 'jalan meninggal', 'truk tangki', 'menyediakan', 'meninggal dunia', 'menyeberang jalan', 'tangki pertamina', 'jalanan', 'madiun kota', 'menabrak pembatas', 'kota madiun', 'pengganti', 'tangki putu', 'kecelakaan menaruh', 'madiun taksi', 'juta', 'dunia aris', 'korban menyeberang', 'putu putu', 'menabrak', 'dunia lokasi', 'ukuran pembatas', 'tean truk', 'menyuruh', 'tertabrak truk', 'tertabrak pengendara', 'menuntun sepeda', 'ketimbang', 'sepeda angin', 'merah putu']\n"
     ]
    }
   ],
   "source": [
    "print(keywordBOW_When)\n",
    "print(hasilrankWhen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j=1\n",
    "\n",
    "testing_data = []\n",
    "\n",
    "tfidf_vectorizer = joblib.load('vectorizer.pkl')\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "    \n",
    "#     hasilWhat=[]\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_What= tfidf_vectorizer.transform(kandidatFixWhat)\n",
    "#     results_what=cosine_similarity(tfidf_matrix, query_vec_What).reshape((-1))\n",
    "#     hasilDokumenWhat.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_What:\n",
    "#         cariW = re.findall(a,hasilDokumenWhat[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWhat.append(a)\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'what',kueriAsliWhat,keywordBOW_What , keywordGabungWhat,kandidatFixWhat, hasilWhat, results_what,' ',' ']\n",
    "\n",
    "#     testing_data.append(data)\n",
    "\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "#     hasilWhere=[]\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_Where= tfidf_vectorizer.transform(kandidatFixWhere)\n",
    "#     results_where=cosine_similarity(tfidf_matrix, query_vec_Where).reshape((-1))\n",
    "#     hasilDokumenWhere.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_Where:\n",
    "#         cariW = re.findall(a,hasilDokumenWhere[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWhere.append(a)\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'where',kueriAsliWhere,keywordBOW_Where , keywordGabungWhere, kandidatFixWhere, hasilWhere, results_where,' ',' ']\n",
    "\n",
    "#     testing_data.append(data)\n",
    "\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "#     hasilWho=[]\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_Who= tfidf_vectorizer.transform(kandidatFixWho)\n",
    "#     results_who=cosine_similarity(tfidf_matrix, query_vec_Who).reshape((-1))\n",
    "#     hasilDokumenWho.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_Who:\n",
    "#         cariW = re.findall(a,hasilDokumenWho[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWho.append(a)\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'who',kueriAsliWho,keywordBOW_Who , keywordGabungWho, kandidatFixWho, hasilWho, results_who,' ',' ']\n",
    "\n",
    "#     testing_data.append(data)\n",
    "\n",
    "for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "    hasilWhen=[]\n",
    "\n",
    "    teks=df_test.iloc[i,-2]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "    query_vec_When= tfidf_vectorizer.transform(kandidatFixWhen)\n",
    "    results_when=cosine_similarity(tfidf_matrix, query_vec_When).reshape((-1))\n",
    "    hasilDokumenWhen.append(df_test.iloc[i,2])\n",
    "    for a in kueriFixWithDelimiter_When:\n",
    "        cariW = re.findall(a,hasilDokumenWhen[i])\n",
    "        #print(cariW)\n",
    "        if cariW:\n",
    "            hasilWhen.append(a)\n",
    "    \n",
    "    data = [i,df_test.iloc[i,2],'when',kueriAsliWhen,keywordBOW_When , keywordGabungWhen, kandidatFixWhen, hasilWhen, results_when,' ',' ']\n",
    "\n",
    "    testing_data.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "writer = pd.DataFrame(testing_data, columns=['No Document','Description', 'W','Pertanyaan', 'Keyword BOW', 'Keyword Gabung','kandidat fix','hasilW', 'Kemiripan', 'True Positif', 'True Negative'])\n",
    "writer.to_csv('QE_Stat_testing_whenTes_result.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
