{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library-library\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation and Preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "# Word Embedding\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "from keybert import KeyBERT\n",
    "kw_extractor = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input and Expansion Query\n",
    "import nltk\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "from yake import KeywordExtractor\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "NLTK_StopWords = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(berita):\n",
    "    s = berita.lower()\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    T = [t for t in tokens if t not in NLTK_StopWords]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27 entries, 0 to 26\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        27 non-null     object\n",
      " 1   date         27 non-null     object\n",
      " 2   description  27 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 864.0+ bytes\n",
      "None\n",
      "------------------------------------------------------------------------------------------\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "df_total = pd.read_csv('df_total.csv')\n",
    "df_total = df_total[pd.notnull(df_total['description'])]\n",
    "print(df_total.info())\n",
    "print ('-'*90)\n",
    "document_text= joblib.load('document_text.pkl')\n",
    "print(len(document_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cari_dokpertama(kueriAsli):\n",
    "    kueriPre=preprocessing(kueriAsli)\n",
    "    kueriPre= \" \".join (kueriPre)\n",
    "    hasilSearch=[]\n",
    "    tfidf_matrix = joblib.load('tfidf.pkl')\n",
    "    tfidf_vectorizer = joblib.load('vectorizer.pkl')\n",
    "    query_vec= tfidf_vectorizer.transform([kueriPre])\n",
    "    results=cosine_similarity(tfidf_matrix, query_vec).reshape((-1))\n",
    "    for i in results.argsort()[-5:][::-1]:\n",
    "        hasilSearch.append(df_total.iloc[i,-1])\n",
    "    hasilSearch=\". \".join(hasilSearch)\n",
    "    return hasilSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Keywords Extraction with YAKE\n",
    "def keyword_yake(hasilSearch):\n",
    "    keywordYake=[]\n",
    "\n",
    "    k_extractor = KeywordExtractor(lan=\"id\", n=1, top=10)\n",
    "    k_extractor2 = KeywordExtractor(lan=\"id\", n=2, top=10)\n",
    "    keywords = k_extractor.extract_keywords(text=hasilSearch)\n",
    "    keywords = k_extractor2.extract_keywords(text=hasilSearch)\n",
    "    keywordYake = [x for x, y in keywords]\n",
    "    #keywordYake.append(keywords)\n",
    "    #print (keywordYake)\n",
    "    return keywordYake\n",
    "#print(\"Keywords of article\\n\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with TFIDF\n",
    "def keyword_tfidf(hasilSearch):\n",
    "\n",
    "    keywordtfidf=[]\n",
    "    keywordtfidf2=[]\n",
    "\n",
    "    #doc = 'بَاب فرض الْوضُوء وسننه وهيآته وَفرض الْوضُوء سِتّ خِصَال النِّيَّة عمند غسل الْوَجْه وَغسل الْوَجْه وَغسل الذراعين مَعَ الْمرْفقين وَمسح مَا قل من الرَّأْس وَغسل الرجلَيْن مَعَ الْكَعْبَيْنِ وَالتَّرْتِيب وعَلى قَول الْوَلَاء وسننه عشر خِصَال خمس مِنْهَا قبل غسل الْوَجْه وَهِي التَّسْمِيَة وَغسل الْكَفَّيْنِ والمضمضة وَالِاسْتِنْشَاق وَالْمُبَالغَة فيههما إِلَّا للصَّائِم وَخمْس بعد غسل الْوَجْه وَهِي تَقْدِيم الْيُمْنَى على ليسرى وَمسح جَمِيع الرَّأْس وَمسح الْأُذُنَيْنِ ظاهرهما وباطنهما وَإِدْخَال الأصبعين فيهمَا وتخليل أَصَابِع الرجلَيْن . وَغسل دَاخل الْكَعْبَيْنِ وَلَيْسَ مسح لعنق من سنَنه وفضيلته تكراره ثَلَاثًا وزالواجب فِيهِ مرّة والمرتان أفضل وَالثَّلَاث أكمل وهيآته أَن يبْدَأ فِي تَطْهِير الْأَعْضَاء بمواضع الِابْتِدَاء . فَإِن اقْتصر على فروضه استة أَجزَأَهُ وَإِن ضيع حَظّ نَفسه فِيمَا ترك'\n",
    "    total_words = re.sub(r'[^\\w]', ' ', hasilSearch)\n",
    "    total_words = total_words.lower().split()\n",
    "    #print (total_words)\n",
    "    total_word_length = len(total_words)\n",
    "    total_sentences = tokenize.sent_tokenize(hasilSearch)\n",
    "    total_sent_len = len(total_sentences)\n",
    "\n",
    "    tf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in tf_score:\n",
    "                tf_score[each_word] += 1\n",
    "            else:\n",
    "                tf_score[each_word] = 1\n",
    "\n",
    "    # Dividing by total_word_length for each dictionary element\n",
    "    tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "    #print(tf_score)\n",
    "    def check_sent(word, sentences): \n",
    "        final = [all([w in x for w in word]) for x in sentences] \n",
    "        sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "        return int(len(sent_len))\n",
    "\n",
    "    idf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in idf_score:\n",
    "                idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "            else:\n",
    "                idf_score[each_word] = 1\n",
    "\n",
    "    # Performing a log and divide\n",
    "    idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "    #print(idf_score)\n",
    "    tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "    #print(tf_idf_score)\n",
    "    def get_top_n(dict_elem, n):\n",
    "        result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "        hasil =list(result.keys())\n",
    "        #print(list(result.keys()))        \n",
    "        return hasil\n",
    "    #print(get_top_n(tf_idf_score, 25))\n",
    "    #print(len(get_top_n(tf_idf_score, 1)))\n",
    "    keywordtfidf.append(get_top_n(tf_idf_score, 25))\n",
    "    for i in range(len(keywordtfidf)):\n",
    "        #print (i)\n",
    "        totalKw=0\n",
    "        totalKw=len(keywordtfidf[i])\n",
    "        for j in range(totalKw):\n",
    "            #print (j)\n",
    "            keywordtfidf2.append(keywordtfidf[i][j])\n",
    "    #print (keywordtfidf2)\n",
    "    return keywordtfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with BERT\n",
    "def keyword_bert(hasilSearch):\n",
    "\n",
    "    keywordbert=[]\n",
    "\n",
    "    #for j in range(len(array_text)):\n",
    "    keyword1 = kw_extractor.extract_keywords(hasilSearch, top_n=10, keyphrase_ngram_range=(1, 1))\n",
    "    keyword2 = kw_extractor.extract_keywords(hasilSearch, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "\n",
    "    #print(\"Keywords of article\\n\", keywords)\n",
    "    for i in range (0,len (keyword1)):\n",
    "        keywordbert.append(keyword1[i][0])\n",
    "        keywordbert.append(keyword2[i][0])\n",
    "    #print (keywordbert)\n",
    "    return keywordbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rangking (keywordGabung,kueriAsli):\n",
    "    kandidatFinalCek=[]\n",
    "    kandidatFinalFix=[]\n",
    "    for i in keywordGabung:\n",
    "        if (i not in kandidatFinalCek and i!=0):\n",
    "            kandidatFinalCek.append(i)\n",
    "    queries=[kueriAsli]\n",
    "    query_embeddings = embedder.encode(queries)\n",
    "    corpus_embeddings4 = embedder.encode(kandidatFinalCek)\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    closest_n = 30\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings4, 'cosine')[0]\n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            kandidatFinalFix.append(kandidatFinalCek[idx])\n",
    "    print ('kandidatFinalFix: ', kandidatFinalFix)\n",
    "    return kandidatFinalFix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pelaku']\n",
      "kandidatFinalFix:  ['berboncengan', 'korban', 'terbantahkan', 'berkaitan', 'luka', 'benda', 'tabrak lari', 'kasubdit', 'berdurasi', 'wafat', 'diambil', 'membenarkan', 'detik', 'kapolres', 'dikemudikan', 'tuduhan', 'zulpan', 'bukti', '1', 'dievakuasi', 'mendekati', 'iya', 'meninggal dunia', 'terpisah', 'viral', 'polda metro', '05', 'sopir taksi', '27', 'informasi']\n",
      "************************************************************************************************************************\n",
      "1\n",
      "No ID Dokumen  :  0\n",
      "Tanggal        :  Minggu, 30 Jan 2022 18:41 WIB\n",
      "\n",
      "\n",
      "Isi berita     :  bikin atap bus raib tabrak flyover sopir diburu polisi sopir bus berkelir merah menabrak kapolres padang akbp novianto taryono sopir bus bernama manalu kabur tabrakan jalan soekarno hatta simpang lapan kota pengendara bus kabur kecelakaan pencarian novianto dikutip peristiwa mengakibatkan atap bus terlepas 17 penumpang mengalami luka luka dirawat rsud padang bus dievakuasi petugas polres kabid humas polda sumbar kombes satake bayu bus melaju arah bukittinggi kota padang sopir bus rute menerobos jalan dilengkapi marka jalan satake dikutip kecepatan bus menghindari tabrakan korban jiwa penumpang mengalami luka luka akibat benturan keras mobil hilang atasnya\n",
      "Hasil W       :  ['korban', 'luka', 'kapolres', '1', 'dievakuasi']\n",
      "(Kemiripan: 0.3313) \n",
      "************************************************************************************************************************\n",
      "2\n",
      "No ID Dokumen  :  1\n",
      "Tanggal        :  Minggu, 30 Jan 2022 17:35 WIB\n",
      "\n",
      "\n",
      "Isi berita     :  mobil tabrak pembatas jalan tol jakarta tangerang pengemudi luka mobil kepala induk pjr tol bitung akp suwito membenarkan kejadian tepatnya km 21 600 b arah jakarta kecelakaan minggu 30 1 2022 14 30 wib minibus bernopol a 1281 xw dikendarai abdul hafid bersenggolan mobil dikenal kaget banting setir mengakibatkan menabrak pembatas tol median jalan akp suwito wartawan pengemudi mobil mengalami luka ringan beruntung korban jiwa peristiwa pengemudi minibus alami luka ringan korban jiwa mobil disenggol kabur melarikan suwito korban mengalami luka ringan dadanya terbentur setir mobil korban dibawa rumah sakit ditangani mobil dievakuasi mobil korban melintang menghadang jalan bersenggolan\n",
      "Hasil W       :  ['korban', 'luka', 'membenarkan', '1', 'dievakuasi']\n",
      "(Kemiripan: 0.3523) \n",
      "************************************************************************************************************************\n",
      "3\n",
      "No ID Dokumen  :  2\n",
      "Tanggal        :  Minggu, 30 Jan 2022 16:27 WIB\n",
      "\n",
      "\n",
      "Isi berita     :  tabrak pembatas jalan tol cisumwadu mobil rusak kecelakaan tunggal tol cisumdawu kali menimpa unit minibus menabrak pembatas jalan km 165 arah bandung sumedang minggu 30 1 2022 mobil avanza warna putih nomor polisi d 1443 aca menabrak pembatas jalan beruntung kendaraan dikendalikan mengalami kerusakan korban panit 2 unit 3 jatiwangi iptu ervan kecelakaan 15 20 wib mobil diisi sang sopir arah bandung sumedang gerbang tol pamulihan diduga akibat mengantuk mobil menabrak pembatas jalan lokasi kejadian mobil bergerak bandung sumedang sang sopir mengantuk lokasi kejadian menabrak pembatas jalan terangnya dihubungi korban peristiwa mobil langsung berhenti kecelakaan alhamdulillah korban mobil dikendalikan dihentikan pungkasnya mobil sedan mengalami kecelakaan tunggal terbalik tol cisumdawu km 166 arah bandung sumedang jawa barat sabtu 29 1 2022 malam korban tewas kejadian orang mengalami luka ringan pantauan petugas kepolisian lokasi mengatur jalannya arus lintas terhambat akibat kejadian panit i unit 3 pjr cisumdawu ipda deny ruchyat kecelakaan tunggal km 166 22 04 wib mobil sedan ditumpangi orang meluncur arah bandung arah sumedang pintu gerbang tol pamulihan deny lokasi kejadian deny mobil menabrak pembatas jalan mobil terpental sebelah kiri mobil terbalik pas km 166 200 mobil menabrak pembatas sisi kiri jalan terpental terbalik terangnya\n",
      "Hasil W       :  ['korban', 'luka', '1']\n",
      "(Kemiripan: 0.1527) \n",
      "************************************************************************************************************************\n",
      "4\n",
      "No ID Dokumen  :  3\n",
      "Tanggal        :  Minggu, 30 Jan 2022 15:43 WIB\n",
      "\n",
      "\n",
      "Isi berita     :  mobil masuk jurang ciamis 2 orang tewas mobil kijang berpenumpang 13 orang jatuh jurang jalan desa panjalu kecamatan panjalu kabupaten ciamis jawa barat minggu 30 1 2022 akibat kecelakaan tunggal 2 orang meninggal dunia sopir 11 orang terluka informasi mobil kijang melaju arah majalengka tasikmalaya turunan diduga rem blong mobil menabrak pohon pinggir jalan masuk jurang terguling mobil mengangkut rombongan keluarga desa sindangwangi kecamatan cikijing kabupaten majalengka warga kejadian langsung menolong korban dievakuasi puskesmas panjalu dirujuk rumah sakit jasa kartini tasikmalaya orang meninggal dunia kapolsek panjalu iptu yaya koswara membenarkan kejadian kecelakaan keterangan saksi mobil rombongan sekeluarga majalengka rencananya mengantar kuliah universitas siliwangi tasikmalaya dugaan mobil mengalami rem blong turunan terguling jurang rumah warga yaya mobil 13 orang penumpang 2 orang meninggal dunia sopir mobil 11 orang terluka dibawa puskesmas panjalu 3 orang dirujuk jasa kartini tasikmalaya kecelakaan ditangani satuan lintas polres ciamis data penumpang mobil kijang mengalami kecelakaan panjalu ciamis 1 wafa aulia 29 alamat dusun sindangpanji desa cikijing majalengka\n",
      "Hasil W       :  ['korban', 'luka', 'membenarkan', '1', 'dievakuasi', 'meninggal dunia', 'informasi']\n",
      "(Kemiripan: 0.2072) \n",
      "************************************************************************************************************************\n",
      "5\n",
      "No ID Dokumen  :  4\n",
      "Tanggal        :  Minggu, 30 Jan 2022 17:21 WIB\n",
      "\n",
      "\n",
      "Isi berita     :  2 insiden kecelakaan tunggal km 165 166 tol cisumdawu dioperasikan 6 selasa 25 1 2022 tercatat kali kecelakaan tunggal tol cisumdawu penyebab pastinya kecelakaan lokasinya km 165 km 166 arah bandung sumedang kecelakaan menimpa sedan toyota vios warna silver bernomor polisi d 1152 jn sabtu 29 1 2022 malam mobil arah bandung sumedang lokasi kejadian km 166 mobil menghantam pembatas jalan terpental posisi mobil terbalik badan jalan korban tewas kejadian orang kendaraan mengalami luka ringan terpaksa dilarikan rumah sakit terdekat perawatan kecelakaan minggu 30 2 2022 sore dimana lokasi kecelakaannya lokasi kecelakaan minibus arah bandung sumedang mengalami kecelakaan tunggal km 165 tol cisundawu sopir mobil avanza warna putih nomor polisi d 1443 aca diduga mengantuk berujung kecelakaan menabrak pembatas jalan beruntung kendaraan dikendali mengalami kerusakan korban panit 2 unit 3 jatiwangi iptu ervan kecelakaan 15 20 wib mobil diisi sang sopir arah bandung sumedang gerbang tol pamulihan diduga akibat mengantuk mobil menabrak pembatas jalan lokasi kejadian mobil bergerak bandung sumedang sang sopir mengantuk lokasi kejadian menabrak pembatas jalan terangnya dihubungi detikcom korban peristiwa mobil langsung berhenti kecelakaan alhamdulillah korban mobil dikendalikan dihentikan pungkasnya\n",
      "Hasil W       :  ['korban', 'luka', 'detik', '1']\n",
      "(Kemiripan: 0.1959) \n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kueriAsli='pelaku'\n",
    "kueri=preprocessing(kueriAsli)\n",
    "kueri= [\" \".join (kueri)]\n",
    "print (kueri)\n",
    "hasilkandidat=[]\n",
    "keywordGabung=[]\n",
    "kandidatFix=[]\n",
    "kueriFix=[]\n",
    "hasilDokumen=[]\n",
    "\n",
    "hasilSearch=cari_dokpertama(kueriAsli)\n",
    "keywordYake=keyword_yake(hasilSearch)\n",
    "keywordtfidf2=keyword_tfidf(hasilSearch)\n",
    "keywordbert=keyword_bert (hasilSearch)\n",
    "for i in keywordYake:\n",
    "    keywordGabung.append(i)\n",
    "for i in keywordtfidf2:\n",
    "    keywordGabung.append(i)\n",
    "for i in keywordbert:\n",
    "    keywordGabung.append(i)\n",
    "hasilrank=rangking(keywordGabung,kueriAsli)\n",
    "for i in hasilrank:\n",
    "    kueriFix.append(i)\n",
    "for j in kueriFix:\n",
    "    hasilkandidat.append(j)\n",
    "kueriFix=[preprocessing(i) for i in kueriFix]\n",
    "for i in kueriFix:\n",
    "    for j in i:\n",
    "        kandidatFix.append(j)\n",
    "kandidatFix= [\" \".join (kandidatFix)]\n",
    "print ('*'*120)\n",
    "j=1\n",
    "for i in range(0, 5):\n",
    "    hasilW=[]\n",
    "    teks=df_total.iloc[i,-1]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "    query_vec= tfidf_vectorizer.transform(kandidatFix)\n",
    "    results=cosine_similarity(tfidf_matrix, query_vec).reshape((-1))\n",
    "    hasilDokumen.append(df_total.iloc[i,2])\n",
    "    for a in hasilrank:\n",
    "        cariW = re.findall(a,hasilDokumen[i])\n",
    "        #print(cariW)\n",
    "        if cariW:\n",
    "            hasilW.append(a)\n",
    "    print (j)\n",
    "    print(\"No ID Dokumen  : \", i)\n",
    "    print(\"Tanggal        : \", df_total.iloc[i,1])\n",
    "    print(\"Isi berita     : \", df_total.iloc[i,2])\n",
    "    print (\"Hasil W       : \",hasilW)\n",
    "    print(\"(Kemiripan: %.4f) \" % results)\n",
    "    print ('*'*120)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kueriAsli='kecelakaan'\n",
    "kueri=preprocessing(kueriAsli)\n",
    "kueri= [\" \".join (kueri)]\n",
    "print (kueri)\n",
    "hasilkandidat=[]\n",
    "keywordGabung=[]\n",
    "kandidatFix=[]\n",
    "kueriFix=[]\n",
    "hasilDokumen=[]\n",
    "hasilSearch=cari_dokpertama(kueriAsli)\n",
    "keywordYake=keyword_yake(hasilSearch)\n",
    "keywordtfidf2=keyword_tfidf(hasilSearch)\n",
    "keywordbert=keyword_bert (hasilSearch)\n",
    "for i in keywordYake:\n",
    "    keywordGabung.append(i)\n",
    "for i in keywordtfidf2:\n",
    "    keywordGabung.append(i)\n",
    "for i in keywordbert:\n",
    "    keywordGabung.append(i)\n",
    "hasilrank=rangking(keywordGabung,kueriAsli)\n",
    "for i in hasilrank:\n",
    "    kueriFix.append(i)\n",
    "for j in kueriFix:\n",
    "    hasilkandidat.append(j)\n",
    "kueriFix=[preprocessing(i) for i in kueriFix]\n",
    "for i in kueriFix:\n",
    "    for j in i:\n",
    "        kandidatFix.append(j)\n",
    "kandidatFix= [\" \".join (kandidatFix)]\n",
    "print ('*'*120)\n",
    "tfidf_matrix =joblib.load( \"tfidf.pkl\" )\n",
    "tfidf_vectorizer = joblib.load( \"vectorizer.pkl\" ) \n",
    "query_vec= tfidf_vectorizer.transform(kandidatFix)\n",
    "results=cosine_similarity(tfidf_matrix, query_vec).reshape((-1))\n",
    "j=1\n",
    "for i in results.argsort()[-10:][::-1]:\n",
    "    print (j)\n",
    "    print(\"No ID Dokumen  : \", i)\n",
    "    print(\"Tanggal        : \", df_total.iloc[i,1])\n",
    "    print(\"Isi berita     : \", df_total.iloc[i,2])\n",
    "    print(\"(Kemiripan: %.4f) \" % results[i])\n",
    "    hasilDokumen.append(df_total.iloc[i,2])\n",
    "    print ('*'*120)\n",
    "    j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
