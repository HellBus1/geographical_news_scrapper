{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ryand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import library-library\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation and Preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "# Word Embedding\n",
    "import joblib\n",
    "from keybert import KeyBERT\n",
    "kw_extractor = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "# Input and Expansion Query\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "from yake import KeywordExtractor\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "NLTK_StopWords = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(berita):\n",
    "    s = berita.lower()\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = s.replace('\\r', ' ')\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    T = [t for t in tokens if (((t.lower() == \"tempat\") or (t.lower() == \"waktu\") or (t.lower() == \"hari\")) or (t not in NLTK_StopWords))]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ta', 'ezks', 'p', 'wse', 'f', 'iwhf', '8pigsiakdcns', 'pa', 'dhfo7p89w', 'btcas9e8finuasen']\n"
     ]
    }
   ],
   "source": [
    "kata=\"ta ezks ,[p;,wse[f, [IWHF 8pigsiakdcns['pa{dhfO7P89w btcas9e8finuasen}]]]] sekali\"\n",
    "print(preprocessing(kata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 147 entries, 0 to 146\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        147 non-null    object\n",
      " 1   date         147 non-null    object\n",
      " 2   description  147 non-null    object\n",
      " 3   source       147 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.7+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------------\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "df_test = df_test[pd.notnull(df_test['description'])]\n",
    "print(df_test.info())\n",
    "print ('-'*90)\n",
    "document_text_test= joblib.load('document_text_test.pkl')\n",
    "print(len(document_text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1314 entries, 0 to 1313\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        1314 non-null   object\n",
      " 1   date         1314 non-null   object\n",
      " 2   description  1314 non-null   object\n",
      " 3   source       1314 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 51.3+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------------\n",
      "1314\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_train = df_train[pd.notnull(df_train['description'])]\n",
    "print(df_train.info())\n",
    "print ('-'*90)\n",
    "document_text_train= joblib.load('document_text_train.pkl')\n",
    "print(len(document_text_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_read(bow):\n",
    "    bow_read = pd.read_csv(bow)\n",
    "    bow_text = []\n",
    "\n",
    "    for i in range(0,bow_read.shape[0]):\n",
    "        if(i not in bow_text and i!=0):\n",
    "            bow_text.append(bow_read.iloc[i,1])\n",
    "        \n",
    "    return(bow_read,bow_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cari_dokpertama(kueriAsli):\n",
    "    kueriPre=preprocessing(kueriAsli)\n",
    "    kueriPre= \" \".join (kueriPre)\n",
    "    hasilSearch=[]\n",
    "    tfidf_train = joblib.load('tfidf_train.pkl')\n",
    "    tfidf_vectorizer = joblib.load('vectorizer.pkl')\n",
    "    query_vec= tfidf_vectorizer.transform([kueriPre])\n",
    "    # print('queryvec')\n",
    "    print(query_vec)\n",
    "    results=cosine_similarity(tfidf_train, query_vec).reshape((-1))\n",
    "    # print(results)\n",
    "    for i in results.argsort()[-5:][::-1]:\n",
    "        hasilSearch.append(df_train.iloc[i,-2])\n",
    "    hasilSearch=\". \".join(hasilSearch)\n",
    "    return hasilSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Keywords Extraction with YAKE\n",
    "def keyword_yake(hasilSearch):\n",
    "    # print(hasilSearch)\n",
    "    keywordYake=[]\n",
    "\n",
    "    k_extractor = KeywordExtractor(lan=\"id\", n=1, top=50)\n",
    "    # print(k_extractor)\n",
    "    k_extractor2 = KeywordExtractor(lan=\"id\", n=2, top=50)\n",
    "    # print(k_extractor2)\n",
    "    keywords = k_extractor.extract_keywords(text=hasilSearch)\n",
    "    # print(\"pertama : \",keywords)\n",
    "    keywords = k_extractor2.extract_keywords(text=hasilSearch)\n",
    "    # print(\"kedua : \",keywords)\n",
    "    keywordYake = [x for x, y in keywords]\n",
    "    # print(keywordYake)\n",
    "    #keywordYake.append(keywords)\n",
    "    # print (keywordYake)\n",
    "    return keywordYake\n",
    "#print(\"Keywords of article\\n\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with TFIDF\n",
    "def keyword_tfidf(hasilSearch):\n",
    "\n",
    "    keywordtfidf=[]\n",
    "    keywordtfidf2=[]\n",
    "\n",
    "    #doc = 'بَاب فرض الْوضُوء وسننه وهيآته وَفرض الْوضُوء سِتّ خِصَال النِّيَّة عمند غسل الْوَجْه وَغسل الْوَجْه وَغسل الذراعين مَعَ الْمرْفقين وَمسح مَا قل من الرَّأْس وَغسل الرجلَيْن مَعَ الْكَعْبَيْنِ وَالتَّرْتِيب وعَلى قَول الْوَلَاء وسننه عشر خِصَال خمس مِنْهَا قبل غسل الْوَجْه وَهِي التَّسْمِيَة وَغسل الْكَفَّيْنِ والمضمضة وَالِاسْتِنْشَاق وَالْمُبَالغَة فيههما إِلَّا للصَّائِم وَخمْس بعد غسل الْوَجْه وَهِي تَقْدِيم الْيُمْنَى على ليسرى وَمسح جَمِيع الرَّأْس وَمسح الْأُذُنَيْنِ ظاهرهما وباطنهما وَإِدْخَال الأصبعين فيهمَا وتخليل أَصَابِع الرجلَيْن . وَغسل دَاخل الْكَعْبَيْنِ وَلَيْسَ مسح لعنق من سنَنه وفضيلته تكراره ثَلَاثًا وزالواجب فِيهِ مرّة والمرتان أفضل وَالثَّلَاث أكمل وهيآته أَن يبْدَأ فِي تَطْهِير الْأَعْضَاء بمواضع الِابْتِدَاء . فَإِن اقْتصر على فروضه استة أَجزَأَهُ وَإِن ضيع حَظّ نَفسه فِيمَا ترك'\n",
    "    total_words = re.sub(r'[^\\w]', ' ', hasilSearch)\n",
    "    total_words = total_words.lower().split()\n",
    "    #print (total_words)\n",
    "    total_word_length = len(total_words)\n",
    "    total_sentences = tokenize.sent_tokenize(hasilSearch)\n",
    "    total_sent_len = len(total_sentences)\n",
    "\n",
    "    tf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in tf_score:\n",
    "                tf_score[each_word] += 1\n",
    "            else:\n",
    "                tf_score[each_word] = 1\n",
    "\n",
    "    # Dividing by total_word_length for each dictionary element\n",
    "    tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "    #print(tf_score)\n",
    "    def check_sent(word, sentences): \n",
    "        final = [all([w in x for w in word]) for x in sentences] \n",
    "        sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "        return int(len(sent_len))\n",
    "\n",
    "    idf_score = {}\n",
    "    for each_word in total_words:\n",
    "        #print (each_word)\n",
    "        each_word = each_word.replace('.','')\n",
    "        if each_word not in NLTK_StopWords:\n",
    "            if each_word in idf_score:\n",
    "                idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "            else:\n",
    "                idf_score[each_word] = 1\n",
    "\n",
    "    # Performing a log and divide\n",
    "    idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "    #print(idf_score)\n",
    "    tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "    #print(tf_idf_score)\n",
    "    def get_top_n(dict_elem, n):\n",
    "        result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "        hasil =list(result.keys())\n",
    "        #print(list(result.keys()))        \n",
    "        return hasil\n",
    "    #print(get_top_n(tf_idf_score, 25))\n",
    "    #print(len(get_top_n(tf_idf_score, 1)))\n",
    "    keywordtfidf.append(get_top_n(tf_idf_score, 35))\n",
    "    for i in range(len(keywordtfidf)):\n",
    "        #print (i)\n",
    "        totalKw=0\n",
    "        totalKw=len(keywordtfidf[i])\n",
    "        for j in range(totalKw):\n",
    "            #print (j)\n",
    "            keywordtfidf2.append(keywordtfidf[i][j])\n",
    "    #print (keywordtfidf2)\n",
    "    return keywordtfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords Extraction with BERT\n",
    "def keyword_bert(hasilSearch):\n",
    "    # print(hasilSearch)\n",
    "\n",
    "    keywordbert=[]\n",
    "\n",
    "    #for j in range(len(array_text)):\n",
    "    keyword1 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 1))\n",
    "    # print(keyword1)\n",
    "    keyword2 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 2))\n",
    "    # print(keyword2)\n",
    "    # keyword3 = kw_extractor.extract_keywords(hasilSearch, top_n=50, keyphrase_ngram_range=(1, 5))\n",
    "    # print(keyword3)\n",
    "\n",
    "    #print(\"Keywords of article\\n\", keywords)\n",
    "    for i in range (0,len (keyword1)):\n",
    "        keywordbert.append(keyword1[i][0])\n",
    "        keywordbert.append(keyword2[i][0])\n",
    "    # print (keywordbert)\n",
    "    # print(len(keywordbert))\n",
    "    return keywordbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasilDokumenWhen=[]\n",
    "# kueriAsliWhen='hari apa waktu terjadinya'\n",
    "# hasilSearch=cari_dokpertama(kueriAsliWhen)\n",
    "# keywordber=keyword_bert(hasilSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rangking (keywordGabung):\n",
    "    keywordTemp=[]\n",
    "    keywordFinal=[]\n",
    "\n",
    "    def borda_sort(lists):\n",
    "        scores = {}\n",
    "        for l in lists:\n",
    "            for idx, elem in enumerate(reversed(l)):\n",
    "                if not elem in scores:\n",
    "                    scores[elem] = 0\n",
    "                scores[elem] += idx\n",
    "        return sorted(scores.keys(), key=lambda elem: scores[elem], reverse=True)\n",
    "\n",
    "    keywordTemp.append(borda_sort(keywordGabung))\n",
    "    print ('kandidat temp',keywordTemp)\n",
    "    print ('Total Kandidat temp: ',len(keywordTemp[0]))\n",
    "\n",
    "    if len(keywordTemp[0])>30:\n",
    "        print ('kurang dari 80')\n",
    "        for i in range (0,80):\n",
    "            keywordFinal.append(keywordTemp[0][i])\n",
    "    elif len(keywordTemp[0])<80:\n",
    "        print ('lebih dari 80')\n",
    "        for i in range (0,len(keywordTemp)):\n",
    "            for j in range (0,len(keywordTemp[0])):\n",
    "                keywordFinal.append(keywordTemp[0][j])\n",
    "    print ('Total Kandidat final: ',len(keywordFinal))\n",
    "    print ('Kandidat final: ',keywordFinal)\n",
    "    return keywordFinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_BOW(keywordBOW, kueriAsli):\n",
    "    cekDuplicate = []\n",
    "    kandidatFix = []\n",
    "\n",
    "    for i in keywordBOW:\n",
    "        if(i not in cekDuplicate and i!=0):\n",
    "            cekDuplicate.append(i)\n",
    "\n",
    "    # queries=[kueriAsli]\n",
    "    queries=kueriAsli\n",
    "    query_embeddings = embedder.encode(queries)\n",
    "    corpus_embeddings4 = embedder.encode(cekDuplicate)\n",
    "    \n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    # closest_n = 1000\n",
    "    closest_n = 2000\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings4, 'cosine')[0]\n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            kandidatFix.append(cekDuplicate[idx])\n",
    "    return kandidatFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kandidatFix(kueriAsli,bow):\n",
    "    #kueri what\n",
    "    # kueriAsli='apa sebenarnya kejadian yang terjadi diberita tersebut'\n",
    "    kueri=preprocessing(kueriAsli)\n",
    "    kueri= [\" \".join (kueri)]\n",
    "    print (kueri)\n",
    "    hasilkandidat=[]\n",
    "    keywordGabung=[]\n",
    "    kandidatFix=[]\n",
    "    kueriFix=[]\n",
    "    kueriFixWithDelimiter=[]\n",
    "    \n",
    "\n",
    "\n",
    "    hasilSearch=cari_dokpertama(kueriAsli)\n",
    "    keywordYake=keyword_yake(hasilSearch)\n",
    "    keywordtfidf2=keyword_tfidf(hasilSearch)\n",
    "    keywordbert=keyword_bert (hasilSearch)\n",
    "    keywordBOW=keyword_BOW(bow, kueri)\n",
    "\n",
    "    keywordGabung.append(keywordYake)\n",
    "    keywordGabung.append(keywordtfidf2)\n",
    "    keywordGabung.append(keywordbert)\n",
    "    # keywordGabung.append(keywordBOW)\n",
    "    hasilrank=rangking(keywordGabung)\n",
    "\n",
    "    for i in hasilrank:\n",
    "        kueriFix.append(i)\n",
    "    for x in keywordBOW:\n",
    "        kueriFix.append(x)\n",
    "    for j in kueriFix:\n",
    "        hasilkandidat.append(j)\n",
    "    kueriFixWithDelimiter=kueriFix\n",
    "    kueriFix=[preprocessing(i) for i in kueriFix]\n",
    "    for i in kueriFix:\n",
    "        for j in i:\n",
    "            kandidatFix.append(j)\n",
    "    kandidatFix= [\" \".join (kandidatFix)]\n",
    "    \n",
    "    print ('*'*120)\n",
    "    return(kandidatFix,keywordGabung,keywordBOW,hasilrank,kueriFixWithDelimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_ekonomi_read,bow_ekonomi_text = bow_read('bow_ekonomi.csv')\n",
    "bow_where_read,bow_where_text = bow_read('bow_where_negara.csv')\n",
    "bow_when_read,bow_when_text = bow_read('bow_when.csv')\n",
    "bow_who_read,bow_who_text = bow_read('bow_who_ekonomi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What     :  perekonomian\n",
      "Where    :  surabaya\n",
      "When     :  waktu\n",
      "Who      :  pelakunya\n"
     ]
    }
   ],
   "source": [
    "print(\"What     : \", bow_ekonomi_text[0])\n",
    "print(\"Where    : \", bow_where_text[0])\n",
    "print(\"When     : \", bow_when_text[0])\n",
    "print(\"Who      : \", bow_who_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tingkat setelah parent</th>\n",
       "      <th>parent</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ekonomi</td>\n",
       "      <td>[('perekonomian', 0.7561678290367126), ('ekono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>perekonomian</td>\n",
       "      <td>[('ekonomi', 0.7561678290367126), ('ekonominya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ekonominya</td>\n",
       "      <td>[('perekonomian', 0.676762044429779), ('ekonom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>politik</td>\n",
       "      <td>[('politiknya', 0.6882383227348328), ('sosial'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>sosial</td>\n",
       "      <td>[('sosialnya', 0.6959102153778076), ('politik'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tingkat setelah parent        parent  \\\n",
       "0                       1       ekonomi   \n",
       "1                       2  perekonomian   \n",
       "2                       2    ekonominya   \n",
       "3                       2       politik   \n",
       "4                       2        sosial   \n",
       "\n",
       "                                          similarity  \n",
       "0  [('perekonomian', 0.7561678290367126), ('ekono...  \n",
       "1  [('ekonomi', 0.7561678290367126), ('ekonominya...  \n",
       "2  [('perekonomian', 0.676762044429779), ('ekonom...  \n",
       "3  [('politiknya', 0.6882383227348328), ('sosial'...  \n",
       "4  [('sosialnya', 0.6959102153778076), ('politik'...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_ekonomi_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tingkat setelah parent</th>\n",
       "      <th>parent</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>[('semarang', 0.7880793213844299), ('malang', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>semarang</td>\n",
       "      <td>[('surabaya', 0.7880793213844299), ('magelang'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>malang</td>\n",
       "      <td>[('surabaya', 0.724402129650116), ('kediri', 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>[('surabaya', 0.6788262724876404), ('bandung',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tingkat setelah parent    parent  \\\n",
       "0                     NaN       NaN   \n",
       "1                     1.0  surabaya   \n",
       "2                     2.0  semarang   \n",
       "3                     2.0    malang   \n",
       "4                     2.0   jakarta   \n",
       "\n",
       "                                          similarity  \n",
       "0                                                NaN  \n",
       "1  [('semarang', 0.7880793213844299), ('malang', ...  \n",
       "2  [('surabaya', 0.7880793213844299), ('magelang'...  \n",
       "3  [('surabaya', 0.724402129650116), ('kediri', 0...  \n",
       "4  [('surabaya', 0.6788262724876404), ('bandung',...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_where_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tingkat setelah parent</th>\n",
       "      <th>parent</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>waktu</td>\n",
       "      <td>[('waktunya', 0.6795573234558105), ('jam', 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>waktunya</td>\n",
       "      <td>[('waktu', 0.6795573830604553), ('hidupnya', 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>jam</td>\n",
       "      <td>[('menit', 0.7242034673690796), ('detik', 0.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>sementara</td>\n",
       "      <td>[('sedangkan', 0.6645538806915283), ('saat', 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tingkat setelah parent     parent  \\\n",
       "0                     NaN        NaN   \n",
       "1                     1.0      waktu   \n",
       "2                     2.0   waktunya   \n",
       "3                     2.0        jam   \n",
       "4                     2.0  sementara   \n",
       "\n",
       "                                          similarity  \n",
       "0                                                NaN  \n",
       "1  [('waktunya', 0.6795573234558105), ('jam', 0.5...  \n",
       "2  [('waktu', 0.6795573830604553), ('hidupnya', 0...  \n",
       "3  [('menit', 0.7242034673690796), ('detik', 0.65...  \n",
       "4  [('sedangkan', 0.6645538806915283), ('saat', 0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_when_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tingkat setelah parent</th>\n",
       "      <th>parent</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pelaku</td>\n",
       "      <td>[('pelakunya', 0.705472469329834), ('tertuduh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pelakunya</td>\n",
       "      <td>[('pembunuhnya', 0.7638124823570251), ('tertud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tertuduh</td>\n",
       "      <td>[('pemerkosa', 0.7687520980834961), ('terdakwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>tersangka</td>\n",
       "      <td>[('terdakwa', 0.7686344385147095), ('tertuduh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>terdakwa</td>\n",
       "      <td>[('tersangka', 0.7686343193054199), ('tertuduh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tingkat setelah parent     parent  \\\n",
       "0                       1     pelaku   \n",
       "1                       2  pelakunya   \n",
       "2                       2   tertuduh   \n",
       "3                       2  tersangka   \n",
       "4                       2   terdakwa   \n",
       "\n",
       "                                          similarity  \n",
       "0  [('pelakunya', 0.705472469329834), ('tertuduh'...  \n",
       "1  [('pembunuhnya', 0.7638124823570251), ('tertud...  \n",
       "2  [('pemerkosa', 0.7687520980834961), ('terdakwa...  \n",
       "3  [('terdakwa', 0.7686344385147095), ('tertuduh'...  \n",
       "4  [('tersangka', 0.7686343193054199), ('tertuduh...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_who_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111\n",
      "1965\n"
     ]
    }
   ],
   "source": [
    "print(len(bow_when_text))\n",
    "cekDuplicate1 = []\n",
    "kandidatFix2 = []\n",
    "\n",
    "for i in bow_ekonomi_text:\n",
    "    if(i not in cekDuplicate1 and i!=0):\n",
    "        cekDuplicate1.append(i)\n",
    "print(len(cekDuplicate1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dimana tempat']\n",
      "  (0, 14506)\t0.6345270345162467\n",
      "  (0, 3890)\t0.7729006679179531\n",
      "kandidat temp [['pengiriman', '2022', '2021 mencapai', '2021', '2021 tumbuh', 'menimbulkan', '2021 kemarin', 'penguatan', '2021 pembentukan', 'masyarakat', 'kekuatan', '2021 pertumbuhan', 'dipertahankan', 'triwulan 2021', '2020', '2021 tercatat', 'pengeluaran', '2022 dunia', 'produk', 'januari 2021', 'mempertahankan', '2021 aktivitas', 'melanjutkan', 'selasa 2022', 'meningkat', '2021 apbn', 'terjangkau', 'oktober 2021', 'kamis 2021', 'mengorbankan', '2021 dimana', 'pusat', '2021 margo', 'juni 2021', 'aktivitas masyarakat', 'menyoroti', '2020 menurutnya', 'peluncuran', 'aktivitas meningkat', 'september 2021', 'beraktivitas', 'menengah', '2020 ketahanan', 'pengetatan', '2021 15', 'kebutuhan', 'mempertahankan menambah', 'pengguna', 'mencapai', '2021 arif', 'dipertahankan perekonomian', 'pertumbuhannya', 'menunjukan penguatan', 'september terkontraksi', 'peningkatan', 'periode september', 'terbaru', 'aktivitas', 'masyarakat beraktivitas', 'ekonomi', 'mempersingkat', 'aktivitas tempat', 'pengiriman 19', 'september level', 'pulau', 'margo aktivitas', 'melanjutkan peluncuran', 'membaik september', 'mengembangkan', 'september', 'masyarakat menengah', 'covid', 'dilanjutkan', 'pertumbuhan ekonomi', 'menimbulkan kerugian', 'september minus', 'mengandalkan', 'perbaikan mobilitas', 'maret 2020', 'pendapatan', 'transit terkontraksi', '5', 'mempertahankan bantuan', 'rekreasi september', '7', 'pembentukan', 'sehari september', '4', 'mengandalkan kekuatan', 'padat aktivitas', 'landainya', 'mencatat', 'aktivitas taman', 'menangani covid', 'tempat', 'seiring', 'tumbuh', 'oktober membaik', 'perubahan kekuatan', 'dibandingkan periode', 'penularan', 'januari', 'oktober', 'pemerintah', 'ruas', 'pengiriman transparan', 'membaik level', 'padat', 'bantuan', 'bergairah', 'ii 2021', 'terkontraksi', 'kepala', 'tutupnya', 'turun aktivitas', 'yuwono', 'dinilainya mempertahankan', 'pemulihan ekonomi', 'data', 'triwulan', 'ekonomi indonesia', 'konferensi', 'dikonsolidasikan merebut', 'berdampak aktivitas', 'pers', 'menjadikan', 'indonesia', 'senin', 'margo yuwono', 'rekreasi', 'margo menghimbau', 'minus', 'mencatat masyarakat', 'mobilitas', 'sehari', 'pengirim', '20', 'harian menimbulkan', 'kenaikan covid', '24', 'kementerian', 'pertumbuhan', 'taman', 'terkontraksi 19', 'yuwono perbaikan', 'transit', 'pendukung', 'tempat wisata', '27', 'pengiriman hendry', 'rendah', 'transparan', 'aktivitas perekonomian', 'normal', 'masyarakat tercatat', 'taman membaik', 'menghimbau', 'perubahan', 'mobilitas berdampak', 'mematuhi', 'angka meningkat', 'kerja terkontraksi', 'protokol', 'pt', 'aktivitas rumah', 'joko', '11 2021', 'perekonomian nasional', 'widodo', 'waktu ruas', 'jokowi', '19 berhubungan', 'penularan covid', 'berhubungan', 'seiring landainya', 'berujung', 'kekuatan konsumsi']]\n",
      "Total Kandidat temp:  177\n",
      "kurang dari 80\n",
      "Total Kandidat final:  80\n",
      "Kandidat final:  ['pengiriman', '2022', '2021 mencapai', '2021', '2021 tumbuh', 'menimbulkan', '2021 kemarin', 'penguatan', '2021 pembentukan', 'masyarakat', 'kekuatan', '2021 pertumbuhan', 'dipertahankan', 'triwulan 2021', '2020', '2021 tercatat', 'pengeluaran', '2022 dunia', 'produk', 'januari 2021', 'mempertahankan', '2021 aktivitas', 'melanjutkan', 'selasa 2022', 'meningkat', '2021 apbn', 'terjangkau', 'oktober 2021', 'kamis 2021', 'mengorbankan', '2021 dimana', 'pusat', '2021 margo', 'juni 2021', 'aktivitas masyarakat', 'menyoroti', '2020 menurutnya', 'peluncuran', 'aktivitas meningkat', 'september 2021', 'beraktivitas', 'menengah', '2020 ketahanan', 'pengetatan', '2021 15', 'kebutuhan', 'mempertahankan menambah', 'pengguna', 'mencapai', '2021 arif', 'dipertahankan perekonomian', 'pertumbuhannya', 'menunjukan penguatan', 'september terkontraksi', 'peningkatan', 'periode september', 'terbaru', 'aktivitas', 'masyarakat beraktivitas', 'ekonomi', 'mempersingkat', 'aktivitas tempat', 'pengiriman 19', 'september level', 'pulau', 'margo aktivitas', 'melanjutkan peluncuran', 'membaik september', 'mengembangkan', 'september', 'masyarakat menengah', 'covid', 'dilanjutkan', 'pertumbuhan ekonomi', 'menimbulkan kerugian', 'september minus', 'mengandalkan', 'perbaikan mobilitas', 'maret 2020', 'pendapatan']\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# hasilDokumenWhen=[]\n",
    "hasilDokumenWho=[]\n",
    "# hasilDokumenWhere=[]\n",
    "# hasilDokumenWhat=[]\n",
    "\n",
    "# kueriAsliWhat='apa yang terjadi diberita tersebut'\n",
    "# kueriAsliWhere='di kota atau negara manakah berita ini '\n",
    "kueriAsliWho='siapa pelaku kegiatan ekonomi dalam berita ini'\n",
    "# kueriAsliWhen='hari apa waktu terjadinya'\n",
    "\n",
    "# kandidatFixWhat,keywordGabungWhat,keywordBOW_What, hasilrankWhat, kueriFixWithDelimiter_What = kandidatFix(kueriAsliWhat, bow_ekonomi_text)\n",
    "# kandidatFixWhere,keywordGabungWhere,keywordBOW_Where, hasilrankWhere,kueriFixWithDelimiter_Where = kandidatFix(kueriAsliWhere, bow_where_text)\n",
    "kandidatFixWho,keywordGabungWho,keywordBOW_Who, hasilrankWho, kueriFixWithDelimiter_Who = kandidatFix(kueriAsliWho, bow_who_text)\n",
    "# kandidatFixWhen,keywordGabungWhen,keywordBOW_When, hasilrankWhen, kueriFixWithDelimiter_When = kandidatFix(kueriAsliWhen, bow_when_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kueriFixWithDelimiter_Where ['pengiriman', '2022', '2021 mencapai', '2021', '2021 tumbuh', 'menimbulkan', '2021 kemarin', 'penguatan', '2021 pembentukan', 'masyarakat', 'kekuatan', '2021 pertumbuhan', 'dipertahankan', 'triwulan 2021', '2020', '2021 tercatat', 'pengeluaran', '2022 dunia', 'produk', 'januari 2021', 'mempertahankan', '2021 aktivitas', 'melanjutkan', 'selasa 2022', 'meningkat', '2021 apbn', 'terjangkau', 'oktober 2021', 'kamis 2021', 'mengorbankan', '2021 dimana', 'pusat', '2021 margo', 'juni 2021', 'aktivitas masyarakat', 'menyoroti', '2020 menurutnya', 'peluncuran', 'aktivitas meningkat', 'september 2021', 'beraktivitas', 'menengah', '2020 ketahanan', 'pengetatan', '2021 15', 'kebutuhan', 'mempertahankan menambah', 'pengguna', 'mencapai', '2021 arif', 'dipertahankan perekonomian', 'pertumbuhannya', 'menunjukan penguatan', 'september terkontraksi', 'peningkatan', 'periode september', 'terbaru', 'aktivitas', 'masyarakat beraktivitas', 'ekonomi', 'mempersingkat', 'aktivitas tempat', 'pengiriman 19', 'september level', 'pulau', 'margo aktivitas', 'melanjutkan peluncuran', 'membaik september', 'mengembangkan', 'september', 'masyarakat menengah', 'covid', 'dilanjutkan', 'pertumbuhan ekonomi', 'menimbulkan kerugian', 'september minus', 'mengandalkan', 'perbaikan mobilitas', 'maret 2020', 'pendapatan', 'bulungan', 'wto', 'kuin', 'temanggung', 'padangsidimpuan', 'diệm', 'sumbersuko', 'tebo', 'olanda', 'karangtengah', 'medan', 'berpulang', 'pagedangan', 'sanana', 'parepare', 'mukomuko', 'perantauan', 'melalang', 'joved', 'srondol', 'jawanya', 'bertualang', 'widjaja', 'barru', 'tasikmalaya', 'kotabumi', 'shikoku', 'perbasi', 'melanglang', 'dahana', 'banjarnegara', 'jammu', 'sangatta', 'marabahan', 'sebuku', 'tuntang', 'sunda', 'lawangan', 'berkelana', 'định', 'kotawaringin', 'temuguruh', 'mempawah', 'merambah', 'kandangan', 'tanahabang', 'pertiba', 'melawat', 'persipare', 'sunter', 'belitung', 'kamulan', 'labuha', 'airlangga', 'pagaralam', 'hakata', 'prembun', 'padangsidempuan', 'pamulang', 'suntec', 'hakka', 'pribumi', 'kerta', 'phạm', 'merawang', 'ujungberung', 'ayutthaya', 'sandakan', 'kinabatangan', 'pademangan', 'kauderni', 'kertanegara', 'perantau', 'jabar', 'temasek', 'temenggong', 'kusumanegara', 'tarumanegara', 'ngemplak', 'selaparang', 'tutong', 'bacan', 'pasai', 'mangkunegaran', 'kedungwaringin', 'kadiri', 'lumajang', 'serawak', 'merangin', 'kauman', 'pannai', 'bedok', 'prapatan', 'kupang', 'promenade', 'kemang', 'kärnten', 'unpar', 'berhad', 'antarnegara', 'pendapa', 'sanya', 'wei', 'kipan', 'sidikalang', 'kentungan', 'beluran', 'tenasserim', 'pakuan', 'bondowoso', 'morowali', 'blambangan', 'punan', 'prancisnya', 'catalunya', 'bumiayu', 'tanggulangin', 'ketapang', 'sepatan', 'palangkaraya', 'rantau', 'terengganu', 'pajajaran', 'tampaksiring', 'petilasan', 'voor', 'kendan', 'beteng', 'gombong', 'sudan', 'cisaat', 'temburong', 'lamongan', 'pangkalpinang', 'manyaran', 'ngruki', 'pekalongan', 'ujungpandang', 'pinrang', 'pilah', 'pengda', 'ryūkyū', 'rukti', 'moencang', 'bahana', 'pajang', 'brumbung', 'mukti', 'hán', 'huế', 'cintapuri', 'soekapoera', 'tabanan', 'labuhan', 'tembilahan', 'kỳ', 'nganjuk', 'tembalang', 'kedah', 'gorontalo', 'sekayu', 'batujajar', 'tanimbar', 'sumedang', 'tamanbaru', 'peranakan', 'balikpapan', 'rukan', 'pusdik', 'pematangsiantar', 'sumbawa', 'kaltara', 'jateng', 'demangan', 'magelang', 'galuh', 'quang', 'permesta', 'pengharepan', 'đại', 'tapos', 'belinyu', 'bubutan', 'prupuk', 'persepar', 'rengat', 'peninjawan', 'teruna', 'ajibarang', 'belait', 'nuku', 'dongguan', 'innermost', 'eea', 'rengas', 'murong', 'tapanuli', 'thanh', 'mahbubah', 'pajarakan', 'kta', 'palembang', 'kundur', 'tanjungpinang', 'nerang', 'tumasik', 'khitan', 'mampang', 'tegal', 'sanglah', 'qom', 'serasan', 'tuva', 'kanjuruhan', 'kalimalang', 'patapan', 'wijk', 'galau', 'bedagai', 'limbang', 'melaka', 'padang', 'sumbar', 'malaka', 'saratok', 'nha', 'jurug', 'tự', 'khánh', 'tiongkok', 'sukolilo', 'mentawai', 'kancana', 'semporna', 'kesiman', 'eaga', 'pulogadung', 'cibiru', 'graha', 'klungkung', 'kendayan', 'pemkab', 'tebingtinggi', 'pejaten', 'sendai', 'mali', 'leitimur', 'xaverian', 'lembang', 'persebaya', 'limbangan', 'cemaga', 'bekasi', 'janggala', 'klaten', 'tohoku', 'puruk', 'demak', 'tangkak', 'sokaraja', 'taipei', 'dương', 'tyas', 'jimbaran', 'tenggarong', 'peterongan', 'kediri', 'pagai', 'bidayuh', 'voc', 'bugis', 'tidung', 'umbulharjo', 'paringin', 'malang', 'malayan', 'pamudja', 'prabu', 'pangkep', 'curahmalang', 'gebang', 'loka', 'persin', 'pamekasan', 'sawarna', 'cibubur', 'khotan', 'kendal', 'muntilan', 'kertosono', 'ngaglik', 'luhak', 'kalibaru', 'bihar', 'kalimantan', 'cianjur', 'pakualaman', 'sovyet', 'persigo', 'asahan', 'unud', 'trần', 'segamat', 'hòa', 'sipitang', 'rembang', 'kalisat', 'rembau', 'darek', 'serdang', 'perseden', 'lempuyangan', 'sungailiat', 'paser', 'cipaku', 'tallo', 'pandeglang', 'asia', 'persekaba', 'murut', 'pte', 'ciampea', 'auvergne', 'rakai', 'jurong', 'qin', 'penang', 'kompeni', 'jogja', 'kedayan', 'kallang', 'bogor', 'nanjing', 'bitung', 'wijayandanu', 'blahbatuh', 'kerinci', 'kalbis', 'bangkalan', 'langat', 'dinh', 'proliga', 'babelan', '上海灘', 'gra', 'arau', 'batanghari', 'supadio', 'jailolo', 'gunma', 'andir', 'seaba', 'busan', 'prov', 'sumba', 'gor', 'pontren', 'muay', 'nonthaburi', 'guang', 'thái', 'tarempa', 'kutoarjo', 'skj', 'kudat', 'gresik', 'resto', 'persada', 'talaud', 'prabumulih', 'balung', 'ktt', 'larang', 'amangkurat', 'izu', 'bengkulu', 'cibadak', 'rijswijk', 'puro', 'sumenep', 'trenggalek', 'langkat', 'enrekang', 'kalbar', 'baturaja', 'taruma', 'guguk', 'stisip', 'haurgeulis', 'tambaksari', 'chí', 'baduy', 'siau', 'magetan', 'plawad', 'kuril', 'parakanmuncang', 'mungkid', 'samarahan', 'picene', 'sragen', 'kejurnas', 'kramatwatu', 'jelutung', 'sarawak', 'navarre', 'wen', 'depok', 'kalapa', 'hebei', 'majapahit', 'đông', 'pleret', 'pringsewu', 'gambringan', 'muar', 'alaman', 'cijeruk', 'kasepuhan', 'omroep', 'selangor', 'ranuyoso', 'cibitung', 'stabas', 'namu', 'sindangkasih', 'kangen', 'konperensi', 'surapati', 'pangandaran', 'pecatu', 'nusantara', 'muaro', 'jombang', 'cinangka', 'makau', 'tobelo', 'lampung', 'qoryati', 'sơn', 'semplak', 'punjab', 'seamolec', 'garut', 'klcc', 'panjalu', 'wisma', 'bulus', 'berau', 'banggai', 'karo', 'kaukasus', 'jepara', 'kalibanteng', 'indragiri', 'unsrat', 'subang', 'pemda', 'nias', 'perspective', 'bangka', 'tegalrejo', 'bric', 'tidore', 'sasak', 'saumlaki', 'soppeng', 'paneropa', 'bretagne', 'tarakan', 'rangkasbitung', 'kuomintang', 'persenga', 'maluku', 'kelantan', 'sampang', 'stikes', 'ampana', 'ploso', 'cibatu', 'blora', 'dayah', 'bojonegoro', 'prakan', 'melak', 'trang', 'padangpanjang', 'buol', 'osce', 'undp', 'sulu', 'panca', 'sumbawan', 'kepahiang', 'mudiak', 'sanata', 'pabuaran', 'pinang', 'pangkajene', 'bengkalis', 'kencana', 'pdra', 'wisesa', 'braunschweig', 'kuntu', 'jamiat', 'parapat', 'bangli', 'simeulue', 'buana', 'caringin', 'krida', 'mercu', 'pakunagara', 'bungku', 'perbaungan', 'immediate', 'dalat', 'derawan', 'condongcatur', 'fremantle', 'taliabu', 'plasa', 'eka', 'kedungjati', 'madiun', 'aluna', 'krung', 'jawa', 'mranggen', 'samudera', 'osaka', 'cipar', 'jogya', 'pepatih', 'unhas', 'silla', 'kunak', 'malut', 'prancis', 'penjajah', 'katumba', 'gigieng', 'tual', 'darma', 'jepangnya', 'pertemuan', 'kts', 'saparua', 'kesunanan', 'kopo', 'siak', 'kopelma', 'karawang', 'meruya', 'parani', 'adiwerna', 'brebes', 'mataram', 'suriname', 'puradiredja', 'pandanaran', 'cepot', 'barus', 'kabuyutan', 'tulungagung', 'poitou', 'tausug', 'pemkot', 'jombor', 'gebu', 'luwu', 'gontor', 'xue', 'batak', 'meiska', 'bintulu', 'ponelo', 'cooktown', 'wonorejo', 'asih', 'jatiwarna', 'waingapu', 'gadingrejo', 'cengkareng', 'gangneung', 'kasunanan', 'batusangkar', 'kalipucang', 'nica', 'hubei', 'persiraja', 'batam', 'namlea', 'efta', 'aomori', 'majalaya', 'oetoesan', 'sanur', 'sidoarjo', 'sukorejo', 'karanganyar', 'cibeber', 'sionggang', 'kampar', 'sulut', 'belanda', 'rouran', 'supermal', 'reskrim', 'perumnas', 'réunion', 'danlanud', 'karimun', 'binh', 'sabah', 'takalar', 'lebak', 'perlawanan', 'invitasi', 'dobo', 'persemalra', 'mamuju', 'istana', 'pekanbaru', 'delri', 'shek', 'andaman', 'pasirian', 'pemprov', 'sumobito', 'kebumen', 'mengwi', 'penh', 'panaikang', 'mergui', 'manise', 'kroya', 'pasaman', 'mangkunagaran', 'sulteng', 'ciluar', 'nederland', 'เก', 'singaraja', 'raharja', 'ettv', 'miri', 'persma', 'kepatihan', 'tumapel', 'memboyong', 'bukittinggi', 'apso', 'butuan', 'kotagede', 'melayu', 'paramita', 'mulya', 'ndalem', 'hồ', 'xu', 'kalteng', 'qing', 'joc', 'karsa', 'kalingga', 'kepanjen', 'bandung', 'sibu', 'pangkor', 'legok', 'ipoh', 'cikampek', 'tigaraksa', 'aniplus', 'pfalz', 'celebes', 'kaili', 'muktamar', 'indraprahasta', 'kopaja', 'tentena', 'brong', 'kahuripan', 'warmadewa', 'clementi', 'purbalingga', 'rogojampi', 'seram', 'vedic', 'bangil', 'cicalengka', 'provinsi', 'niigata', 'suruaso', 'amuntai', 'husada', 'thüringen', 'kuantan', 'gangtok', 'ranai', 'maanyan', 'lombok', 'natuna', 'enok', 'isan', 'hoklo', 'secaba', 'nederlands', 'ciranjang', 'halmahera', 'sukoharjo', 'lipis', 'paiton', 'otago', 'purwosari', 'qi', 'kartasura', 'algemeen', 'naha', 'simboro', 'citeureup', 'menado', 'sidomukti', 'ming', 'antillen', 'rajasthan', 'bintan', 'patani', 'kertapati', 'kunta', 'overland', 'kudarat', 'jembrana', 'akasa', 'wirjawan', 'toronto', 'marseille', 'grha', 'telltale', 'muko', 'tawau', 'rsia', 'badung', 'nederlandsch', 'bagelen', 'buleleng', 'cimahi', 'antilles', 'kremlin', 'gladag', 'yunaninya', 'launceston', 'nepal', 'permai', 'metromini', 'choson', 'malacca', 'hadiningrat', 'yue', 'klakah', 'ibl', 'việt', 'purwokerto', 'argiope', 'blitar', 'han', 'beijing', 'hadiprojo', 'cinere', 'slipi', 'psap', 'pusdikpassus', 'bsi', 'bajawa', 'poris', 'rokan', 'wu', 'aff', 'tungkal', 'mamak', 'jolo', 'mindanao', 'propinsi', 'manado', 'samudra', 'afonso', 'pemalang', 'madura', 'tweede', 'banten', 'dmi', 'tembesi', 'karangjati', 'klender', 'kluang', 'solor', 'tang', 'pommern', 'pattaya', 'ternate', 'serpong', 'deli', 'togean', 'setako', 'brussel', 'masumai', 'padalarang', 'purwodadi', 'banyumas', 'brunai', 'diboncengi', 'minangkabau', 'jebres', 'kisar', 'cileunyi', 'persih', 'yunnan', 'tomohon', 'rudana', 'kolaka', 'sirih', 'ciawi', 'esplanade', 'aljir', 'fernão', 'harbin', 'gwk', 'binjai', 'sukhumvit', 'penjajahan', 'idda', 'epicentrum', 'sarolangun', 'jermanː', 'mataraman', 'varsities', 'lebaksiu', 'bhd', 'lekatompessy', 'amerka', 'imf', 'pagaruyung', 'cipanas', 'fretilin', 'makassar', 'cilacap', 'jatiroto', 'varsity', 'amahai', 'sofifi', 'firenze', 'jro', 'muhamadiyah', 'nederlandse', 'ciherang', 'hessen', 'sukamulya', 'pasuruan', 'kepri', 'perssin', 'canda', 'taichung', 'stichting', 'sulawesi', 'birtania', 'pusdiklatpassus', 'dayak', 'sukasari', 'kunming', 'travail', 'gianyar', 'ehime', 'afnei', 'cideng', 'jember', 'kucha', 'glasgow', 'lubuklinggau', 'ungaran', 'suar', 'ibraninya', 'belleplaine', 'qingdao', 'pyeongan', 'bule', 'kuching', 'saarc', 'gema', 'huygen', 'hindia', 'babadan', 'manahan', 'buntok', 'wolio', 'perth', 'sigli', 'riau', 'ripstore', 'cigudeg', 'wef', 'dansatpom', 'brisbane', 'larantuka', 'purworejo', 'leles', 'kumala', 'sukatani', 'weleri', 'banjarbaru', 'involving', 'toraja', 'bajau', 'kmt', 'bombana', 'senkaku', 'temerloh', 'jatim', 'serian', 'coastal', 'anambas', 'gelgel', 'bontang', 'queenstown', 'ahmadiyya', 'saenuri', 'srono', 'persipura', 'jakarta', 'pires', 'koasi', 'administratie', 'widyatmaka', 'luwuk', 'beiyang', 'situbondo', 'pontianak', 'phuket', 'persiba', 'kendari', 'alahan', 'sawahlunto', 'ubud', 'balam', 'bombay', 'xuan', 'psbl', 'langkawi', 'pelalawan', 'bpn', 'kulonprogo', 'peliatan', 'cikudapateuh', 'buitenzorg', 'siam', 'persipal', 'oostindische', 'basuta', 'bintoro', 'karelia', 'singtel', 'bulukumba', 'eec', 'weihai', 'sibolga', 'oceania', 'amami', 'vajrayana', 'platz', 'lagan', 'mayasari', 'ambon', 'brata', 'ostrobothnia', 'sinjai', 'sukabumi', 'wakapolda', 'jepang', 'keraton', 'speaking', 'jogjakarta', 'serang', 'cotaiarena', 'tuban', 'genta', 'singojuruh', 'dhoho', 'danlanal', 'limapuluh', 'irlandia', 'cipamokolan', 'genoa', 'kertanagara', 'asian', 'manggala', 'konfrensi', 'lippo', 'escap', 'sultra']\n",
      "keywordBOW_Where ['bulungan', 'wto', 'kuin', 'temanggung', 'padangsidimpuan', 'diệm', 'sumbersuko', 'tebo', 'olanda', 'karangtengah', 'medan', 'berpulang', 'pagedangan', 'sanana', 'parepare', 'mukomuko', 'perantauan', 'melalang', 'joved', 'srondol', 'jawanya', 'bertualang', 'widjaja', 'barru', 'tasikmalaya', 'kotabumi', 'shikoku', 'perbasi', 'melanglang', 'dahana', 'banjarnegara', 'jammu', 'sangatta', 'marabahan', 'sebuku', 'tuntang', 'sunda', 'lawangan', 'berkelana', 'định', 'kotawaringin', 'temuguruh', 'mempawah', 'merambah', 'kandangan', 'tanahabang', 'pertiba', 'melawat', 'persipare', 'sunter', 'belitung', 'kamulan', 'labuha', 'airlangga', 'pagaralam', 'hakata', 'prembun', 'padangsidempuan', 'pamulang', 'suntec', 'hakka', 'pribumi', 'kerta', 'phạm', 'merawang', 'ujungberung', 'ayutthaya', 'sandakan', 'kinabatangan', 'pademangan', 'kauderni', 'kertanegara', 'perantau', 'jabar', 'temasek', 'temenggong', 'kusumanegara', 'tarumanegara', 'ngemplak', 'selaparang', 'tutong', 'bacan', 'pasai', 'mangkunegaran', 'kedungwaringin', 'kadiri', 'lumajang', 'serawak', 'merangin', 'kauman', 'pannai', 'bedok', 'prapatan', 'kupang', 'promenade', 'kemang', 'kärnten', 'unpar', 'berhad', 'antarnegara', 'pendapa', 'sanya', 'wei', 'kipan', 'sidikalang', 'kentungan', 'beluran', 'tenasserim', 'pakuan', 'bondowoso', 'morowali', 'blambangan', 'punan', 'prancisnya', 'catalunya', 'bumiayu', 'tanggulangin', 'ketapang', 'sepatan', 'palangkaraya', 'rantau', 'terengganu', 'pajajaran', 'tampaksiring', 'petilasan', 'voor', 'kendan', 'beteng', 'gombong', 'sudan', 'cisaat', 'temburong', 'lamongan', 'pangkalpinang', 'manyaran', 'ngruki', 'pekalongan', 'ujungpandang', 'pinrang', 'pilah', 'pengda', 'ryūkyū', 'rukti', 'moencang', 'bahana', 'pajang', 'brumbung', 'mukti', 'hán', 'huế', 'cintapuri', 'soekapoera', 'tabanan', 'labuhan', 'tembilahan', 'kỳ', 'nganjuk', 'tembalang', 'kedah', 'gorontalo', 'sekayu', 'batujajar', 'tanimbar', 'sumedang', 'tamanbaru', 'peranakan', 'balikpapan', 'rukan', 'pusdik', 'pematangsiantar', 'sumbawa', 'kaltara', 'jateng', 'demangan', 'magelang', 'galuh', 'quang', 'permesta', 'pengharepan', 'đại', 'tapos', 'belinyu', 'bubutan', 'prupuk', 'persepar', 'rengat', 'peninjawan', 'teruna', 'ajibarang', 'belait', 'nuku', 'dongguan', 'innermost', 'eea', 'rengas', 'murong', 'tapanuli', 'thanh', 'mahbubah', 'pajarakan', 'kta', 'palembang', 'kundur', 'tanjungpinang', 'nerang', 'tumasik', 'khitan', 'mampang', 'tegal', 'sanglah', 'qom', 'serasan', 'tuva', 'kanjuruhan', 'kalimalang', 'patapan', 'wijk', 'galau', 'bedagai', 'limbang', 'melaka', 'padang', 'sumbar', 'malaka', 'saratok', 'nha', 'jurug', 'tự', 'khánh', 'tiongkok', 'sukolilo', 'mentawai', 'kancana', 'semporna', 'kesiman', 'eaga', 'pulogadung', 'cibiru', 'graha', 'klungkung', 'kendayan', 'pemkab', 'tebingtinggi', 'pejaten', 'sendai', 'mali', 'leitimur', 'xaverian', 'lembang', 'persebaya', 'limbangan', 'cemaga', 'bekasi', 'janggala', 'klaten', 'tohoku', 'puruk', 'demak', 'tangkak', 'sokaraja', 'taipei', 'dương', 'tyas', 'jimbaran', 'tenggarong', 'peterongan', 'kediri', 'pagai', 'bidayuh', 'voc', 'bugis', 'tidung', 'umbulharjo', 'paringin', 'malang', 'malayan', 'pamudja', 'prabu', 'pangkep', 'curahmalang', 'gebang', 'loka', 'persin', 'pamekasan', 'sawarna', 'cibubur', 'khotan', 'kendal', 'muntilan', 'kertosono', 'ngaglik', 'luhak', 'kalibaru', 'bihar', 'kalimantan', 'cianjur', 'pakualaman', 'sovyet', 'persigo', 'asahan', 'unud', 'trần', 'segamat', 'hòa', 'sipitang', 'rembang', 'kalisat', 'rembau', 'darek', 'serdang', 'perseden', 'lempuyangan', 'sungailiat', 'paser', 'cipaku', 'tallo', 'pandeglang', 'asia', 'persekaba', 'murut', 'pte', 'ciampea', 'auvergne', 'rakai', 'jurong', 'qin', 'penang', 'kompeni', 'jogja', 'kedayan', 'kallang', 'bogor', 'nanjing', 'bitung', 'wijayandanu', 'blahbatuh', 'kerinci', 'kalbis', 'bangkalan', 'langat', 'dinh', 'proliga', 'babelan', '上海灘', 'gra', 'arau', 'batanghari', 'supadio', 'jailolo', 'gunma', 'andir', 'seaba', 'busan', 'prov', 'sumba', 'gor', 'pontren', 'muay', 'nonthaburi', 'guang', 'thái', 'tarempa', 'kutoarjo', 'skj', 'kudat', 'gresik', 'resto', 'persada', 'talaud', 'prabumulih', 'balung', 'ktt', 'larang', 'amangkurat', 'izu', 'bengkulu', 'cibadak', 'rijswijk', 'puro', 'sumenep', 'trenggalek', 'langkat', 'enrekang', 'kalbar', 'baturaja', 'taruma', 'guguk', 'stisip', 'haurgeulis', 'tambaksari', 'chí', 'baduy', 'siau', 'magetan', 'plawad', 'kuril', 'parakanmuncang', 'mungkid', 'samarahan', 'picene', 'sragen', 'kejurnas', 'kramatwatu', 'jelutung', 'sarawak', 'navarre', 'wen', 'depok', 'kalapa', 'hebei', 'majapahit', 'đông', 'pleret', 'pringsewu', 'gambringan', 'muar', 'alaman', 'cijeruk', 'kasepuhan', 'omroep', 'selangor', 'ranuyoso', 'cibitung', 'stabas', 'namu', 'sindangkasih', 'kangen', 'konperensi', 'surapati', 'pangandaran', 'pecatu', 'nusantara', 'muaro', 'jombang', 'cinangka', 'makau', 'tobelo', 'lampung', 'qoryati', 'sơn', 'semplak', 'punjab', 'seamolec', 'garut', 'klcc', 'panjalu', 'wisma', 'bulus', 'berau', 'banggai', 'karo', 'kaukasus', 'jepara', 'kalibanteng', 'indragiri', 'unsrat', 'subang', 'pemda', 'nias', 'perspective', 'bangka', 'tegalrejo', 'bric', 'tidore', 'sasak', 'saumlaki', 'soppeng', 'paneropa', 'bretagne', 'tarakan', 'rangkasbitung', 'kuomintang', 'persenga', 'maluku', 'kelantan', 'sampang', 'stikes', 'ampana', 'ploso', 'cibatu', 'blora', 'dayah', 'bojonegoro', 'prakan', 'melak', 'trang', 'padangpanjang', 'buol', 'osce', 'undp', 'sulu', 'panca', 'sumbawan', 'kepahiang', 'mudiak', 'sanata', 'pabuaran', 'pinang', 'pangkajene', 'bengkalis', 'kencana', 'pdra', 'wisesa', 'braunschweig', 'kuntu', 'jamiat', 'parapat', 'bangli', 'simeulue', 'buana', 'caringin', 'krida', 'mercu', 'pakunagara', 'bungku', 'perbaungan', 'immediate', 'dalat', 'derawan', 'condongcatur', 'fremantle', 'taliabu', 'plasa', 'eka', 'kedungjati', 'madiun', 'aluna', 'krung', 'jawa', 'mranggen', 'samudera', 'osaka', 'cipar', 'jogya', 'pepatih', 'unhas', 'silla', 'kunak', 'malut', 'prancis', 'penjajah', 'katumba', 'gigieng', 'tual', 'darma', 'jepangnya', 'pertemuan', 'kts', 'saparua', 'kesunanan', 'kopo', 'siak', 'kopelma', 'karawang', 'meruya', 'parani', 'adiwerna', 'brebes', 'mataram', 'suriname', 'puradiredja', 'pandanaran', 'cepot', 'barus', 'kabuyutan', 'tulungagung', 'poitou', 'tausug', 'pemkot', 'jombor', 'gebu', 'luwu', 'gontor', 'xue', 'batak', 'meiska', 'bintulu', 'ponelo', 'cooktown', 'wonorejo', 'asih', 'jatiwarna', 'waingapu', 'gadingrejo', 'cengkareng', 'gangneung', 'kasunanan', 'batusangkar', 'kalipucang', 'nica', 'hubei', 'persiraja', 'batam', 'namlea', 'efta', 'aomori', 'majalaya', 'oetoesan', 'sanur', 'sidoarjo', 'sukorejo', 'karanganyar', 'cibeber', 'sionggang', 'kampar', 'sulut', 'belanda', 'rouran', 'supermal', 'reskrim', 'perumnas', 'réunion', 'danlanud', 'karimun', 'binh', 'sabah', 'takalar', 'lebak', 'perlawanan', 'invitasi', 'dobo', 'persemalra', 'mamuju', 'istana', 'pekanbaru', 'delri', 'shek', 'andaman', 'pasirian', 'pemprov', 'sumobito', 'kebumen', 'mengwi', 'penh', 'panaikang', 'mergui', 'manise', 'kroya', 'pasaman', 'mangkunagaran', 'sulteng', 'ciluar', 'nederland', 'เก', 'singaraja', 'raharja', 'ettv', 'miri', 'persma', 'kepatihan', 'tumapel', 'memboyong', 'bukittinggi', 'apso', 'butuan', 'kotagede', 'melayu', 'paramita', 'mulya', 'ndalem', 'hồ', 'xu', 'kalteng', 'qing', 'joc', 'karsa', 'kalingga', 'kepanjen', 'bandung', 'sibu', 'pangkor', 'legok', 'ipoh', 'cikampek', 'tigaraksa', 'aniplus', 'pfalz', 'celebes', 'kaili', 'muktamar', 'indraprahasta', 'kopaja', 'tentena', 'brong', 'kahuripan', 'warmadewa', 'clementi', 'purbalingga', 'rogojampi', 'seram', 'vedic', 'bangil', 'cicalengka', 'provinsi', 'niigata', 'suruaso', 'amuntai', 'husada', 'thüringen', 'kuantan', 'gangtok', 'ranai', 'maanyan', 'lombok', 'natuna', 'enok', 'isan', 'hoklo', 'secaba', 'nederlands', 'ciranjang', 'halmahera', 'sukoharjo', 'lipis', 'paiton', 'otago', 'purwosari', 'qi', 'kartasura', 'algemeen', 'naha', 'simboro', 'citeureup', 'menado', 'sidomukti', 'ming', 'antillen', 'rajasthan', 'bintan', 'patani', 'kertapati', 'kunta', 'overland', 'kudarat', 'jembrana', 'akasa', 'wirjawan', 'toronto', 'marseille', 'grha', 'telltale', 'muko', 'tawau', 'rsia', 'badung', 'nederlandsch', 'bagelen', 'buleleng', 'cimahi', 'antilles', 'kremlin', 'gladag', 'yunaninya', 'launceston', 'nepal', 'permai', 'metromini', 'choson', 'malacca', 'hadiningrat', 'yue', 'klakah', 'ibl', 'việt', 'purwokerto', 'argiope', 'blitar', 'han', 'beijing', 'hadiprojo', 'cinere', 'slipi', 'psap', 'pusdikpassus', 'bsi', 'bajawa', 'poris', 'rokan', 'wu', 'aff', 'tungkal', 'mamak', 'jolo', 'mindanao', 'propinsi', 'manado', 'samudra', 'afonso', 'pemalang', 'madura', 'tweede', 'banten', 'dmi', 'tembesi', 'karangjati', 'klender', 'kluang', 'solor', 'tang', 'pommern', 'pattaya', 'ternate', 'serpong', 'deli', 'togean', 'setako', 'brussel', 'masumai', 'padalarang', 'purwodadi', 'banyumas', 'brunai', 'diboncengi', 'minangkabau', 'jebres', 'kisar', 'cileunyi', 'persih', 'yunnan', 'tomohon', 'rudana', 'kolaka', 'sirih', 'ciawi', 'esplanade', 'aljir', 'fernão', 'harbin', 'gwk', 'binjai', 'sukhumvit', 'penjajahan', 'idda', 'epicentrum', 'sarolangun', 'jermanː', 'mataraman', 'varsities', 'lebaksiu', 'bhd', 'lekatompessy', 'amerka', 'imf', 'pagaruyung', 'cipanas', 'fretilin', 'makassar', 'cilacap', 'jatiroto', 'varsity', 'amahai', 'sofifi', 'firenze', 'jro', 'muhamadiyah', 'nederlandse', 'ciherang', 'hessen', 'sukamulya', 'pasuruan', 'kepri', 'perssin', 'canda', 'taichung', 'stichting', 'sulawesi', 'birtania', 'pusdiklatpassus', 'dayak', 'sukasari', 'kunming', 'travail', 'gianyar', 'ehime', 'afnei', 'cideng', 'jember', 'kucha', 'glasgow', 'lubuklinggau', 'ungaran', 'suar', 'ibraninya', 'belleplaine', 'qingdao', 'pyeongan', 'bule', 'kuching', 'saarc', 'gema', 'huygen', 'hindia', 'babadan', 'manahan', 'buntok', 'wolio', 'perth', 'sigli', 'riau', 'ripstore', 'cigudeg', 'wef', 'dansatpom', 'brisbane', 'larantuka', 'purworejo', 'leles', 'kumala', 'sukatani', 'weleri', 'banjarbaru', 'involving', 'toraja', 'bajau', 'kmt', 'bombana', 'senkaku', 'temerloh', 'jatim', 'serian', 'coastal', 'anambas', 'gelgel', 'bontang', 'queenstown', 'ahmadiyya', 'saenuri', 'srono', 'persipura', 'jakarta', 'pires', 'koasi', 'administratie', 'widyatmaka', 'luwuk', 'beiyang', 'situbondo', 'pontianak', 'phuket', 'persiba', 'kendari', 'alahan', 'sawahlunto', 'ubud', 'balam', 'bombay', 'xuan', 'psbl', 'langkawi', 'pelalawan', 'bpn', 'kulonprogo', 'peliatan', 'cikudapateuh', 'buitenzorg', 'siam', 'persipal', 'oostindische', 'basuta', 'bintoro', 'karelia', 'singtel', 'bulukumba', 'eec', 'weihai', 'sibolga', 'oceania', 'amami', 'vajrayana', 'platz', 'lagan', 'mayasari', 'ambon', 'brata', 'ostrobothnia', 'sinjai', 'sukabumi', 'wakapolda', 'jepang', 'keraton', 'speaking', 'jogjakarta', 'serang', 'cotaiarena', 'tuban', 'genta', 'singojuruh', 'dhoho', 'danlanal', 'limapuluh', 'irlandia', 'cipamokolan', 'genoa', 'kertanagara', 'asian', 'manggala', 'konfrensi', 'lippo', 'escap', 'sultra']\n"
     ]
    }
   ],
   "source": [
    "# print(\"kueriFixWithDelimiter_When\", kueriFixWithDelimiter_When)\n",
    "# print(\"keywordBOW_When\", keywordBOW_When)\n",
    "\n",
    "print(\"kueriFixWithDelimiter_Who\", kueriFixWithDelimiter_Who)\n",
    "print(\"keywordBOW_Who\", keywordBOW_Who)\n",
    "\n",
    "# print(\"kueriFixWithDelimiter_Where\", kueriFixWithDelimiter_Where)\n",
    "# print(\"keywordBOW_Where\", keywordBOW_Where)\n",
    "\n",
    "# print(\"kueriFixWithDelimiter_What\", kueriFixWithDelimiter_What)\n",
    "# print(\"keywordBOW_What\", keywordBOW_What)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ryand\\OneDrive\\TA\\geographical_news_scrapper\\QE Statistik\\QE Statistik.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39m# j=1\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=2'>3</a>\u001b[0m testing_data \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=4'>5</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mvectorizer.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=6'>7</a>\u001b[0m \u001b[39m#What\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=7'>8</a>\u001b[0m \u001b[39m# for i in range(0, len(document_text_test)-1):\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=8'>9</a>\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=26'>27</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=27'>28</a>\u001b[0m \u001b[39m#Where\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryand/OneDrive/TA/geographical_news_scrapper/QE%20Statistik/QE%20Statistik.ipynb#ch0000023?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(document_text_test)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "# j=1\n",
    "\n",
    "testing_data = []\n",
    "\n",
    "tfidf_vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "#What\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "    \n",
    "#     hasilWhat=[]\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_What= tfidf_vectorizer.transform(kandidatFixWhat)\n",
    "#     results_what=cosine_similarity(tfidf_matrix, query_vec_What).reshape((-1))\n",
    "#     hasilDokumenWhat.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_What:\n",
    "#         cariW = re.findall(a,hasilDokumenWhat[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWhat.append(a)\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'what',kueriAsliWhat,keywordBOW_What , keywordGabungWhat,kandidatFixWhat, hasilWhat, results_what,' ',' ']\n",
    "\n",
    "#     testing_data.append(data)\n",
    "\n",
    "#Where\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "#     hasilWhere=[]\n",
    "#     truePos = 0\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_Where= tfidf_vectorizer.transform(kandidatFixWhere)\n",
    "#     results_where=cosine_similarity(tfidf_matrix, query_vec_Where).reshape((-1))\n",
    "#     hasilDokumenWhere.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_Where:\n",
    "#         cariW = re.findall(a,hasilDokumenWhere[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWhere.append(a)\n",
    "#     # print(hasilWhere)\n",
    "#     for x in hasilWhere:\n",
    "#         for y in keywordBOW_Where:\n",
    "#             if(x == y):\n",
    "#                 truePos=1\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'where',kueriAsliWhere,keywordBOW_Where , keywordGabungWhere, kandidatFixWhere, hasilWhere, results_where,truePos,' ']\n",
    "\n",
    "#     testing_data.append(data)\n",
    "\n",
    "#Who\n",
    "for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "    hasilWho=[]\n",
    "\n",
    "    teks=df_test.iloc[i,-2]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "    query_vec_Who= tfidf_vectorizer.transform(kandidatFixWho)\n",
    "    results_who=cosine_similarity(tfidf_matrix, query_vec_Who).reshape((-1))\n",
    "    hasilDokumenWho.append(df_test.iloc[i,2])\n",
    "    for a in kueriFixWithDelimiter_Who:\n",
    "        cariW = re.findall(a,hasilDokumenWho[i])\n",
    "        #print(cariW)\n",
    "        if cariW:\n",
    "            hasilWho.append(a)\n",
    "    \n",
    "    data = [i,df_test.iloc[i,2],'who',kueriAsliWho,keywordBOW_Who , keywordGabungWho, kandidatFixWho, hasilWho, results_who,' ',' ']\n",
    "\n",
    "    testing_data.append(data)\n",
    "\n",
    "#When\n",
    "# for i in range(0, len(document_text_test)-1):\n",
    "\n",
    "#     hasilWhen=[]\n",
    "\n",
    "#     teks=df_test.iloc[i,-2]\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform([teks])\n",
    "\n",
    "#     query_vec_When= tfidf_vectorizer.transform(kandidatFixWhen)\n",
    "#     results_when=cosine_similarity(tfidf_matrix, query_vec_When).reshape((-1))\n",
    "#     hasilDokumenWhen.append(df_test.iloc[i,2])\n",
    "#     for a in kueriFixWithDelimiter_When:\n",
    "#         cariW = re.findall(a,hasilDokumenWhen[i])\n",
    "#         #print(cariW)\n",
    "#         if cariW:\n",
    "#             hasilWhen.append(a)\n",
    "    \n",
    "#     data = [i,df_test.iloc[i,2],'when',kueriAsliWhen,keywordBOW_When , keywordGabungWhen, kandidatFixWhen, hasilWhen, results_when,' ',' ']\n",
    "\n",
    "#     testing_data.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "writer = pd.DataFrame(testing_data, columns=['No Document','Description', 'W','Pertanyaan', 'Keyword BOW', 'Keyword Gabung','kandidat fix','hasilW', 'Kemiripan', 'True Positif', 'True Negative'])\n",
    "writer.to_csv('QE_Stat_testing_who.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
